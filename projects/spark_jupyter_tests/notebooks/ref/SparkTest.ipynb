{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "available-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razor import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collectible-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessory-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor.flow as rf\n",
    "from razor.flow.spark import SparkBlock, SparkExecutor\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from typing import Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outer-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secure-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@rf.block\n",
    "class ReadCsvProjectSpace(SparkBlock):\n",
    "    \n",
    "    __publish__ = True\n",
    "    __label__ = \"Spark read csv block\"\n",
    "    __description__ = \"Read a csv file from project space and output as a spark dataframe\"\n",
    "    __tags__ = [\"spark\", \"filter\", \"big data\",\"csv\",\"projectspace\"]\n",
    "    __category__ = \"Spark\"\n",
    "#     __technology__ = razor.Technology.SPARK\n",
    "    \n",
    "    # Atomic input - csv filename relative to project space\n",
    "    filename:str\n",
    "    # Atomic output of type spark DataFrame.\n",
    "    data: rf.Output[DataFrame]\n",
    "    \n",
    "    def run(self):\n",
    "        path = api.datasources(\"Project Space\").abspath()\n",
    "        df = self.spark.read.csv(os.path.join(path, self.filename), header = True)\n",
    "        df.printSchema()\n",
    "        self.data.put(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "junior-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv_project_space = ReadCsvProjectSpace(filename=\"boston_housing.csv\",config={},source=\"\") \n",
    "read_csv_project_space.executor = SparkExecutor\n",
    "# following are the data types of inputs\n",
    "# (filename -> string)\n",
    "# (config -> dict)\n",
    "# (source -> string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "monthly-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block\n",
    "class RandomProcess(SparkBlock):\n",
    "    \n",
    "    __publish__ = True\n",
    "    __label__ = \"Spark read csv block\"\n",
    "    __description__ = \"Read a csv file from project space and output as a spark dataframe\"\n",
    "    __tags__ = [\"spark\", \"filter\", \"big data\",\"csv\",\"projectspace\"]\n",
    "    __category__ = \"Spark\"\n",
    "#     __technology__ = razor.Technology.SPARK\n",
    "    \n",
    "    # Atomic input - csv filename relative to project space\n",
    "    ip_data:DataFrame\n",
    "    # Atomic output of type spark DataFrame.\n",
    "    op_data: rf.Output[DataFrame]\n",
    "    \n",
    "    def run(self):\n",
    "        ipd = self.ip_data.withColumn(\"b\", self.ip_data[\"b\"].cast(DoubleType()))\n",
    "        ipd = ipd.groupBy(\"zn\").sum(\"b\")\n",
    "        self.op_data.put(ipd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "environmental-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_process = RandomProcess(ip_data=read_csv_project_space.data,config={},source=\"\") \n",
    "random_process.executor = SparkExecutor\n",
    "# following are the data types of inputs\n",
    "# (ip_data -> null)\n",
    "# (config -> dict)\n",
    "# (source -> string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spare-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block\n",
    "class SparkWrite(SparkBlock):\n",
    "    \n",
    "    __publish__ = True\n",
    "    __label__ = \"Spark read csv block\"\n",
    "    __description__ = \"Read a csv file from project space and output as a spark dataframe\"\n",
    "    __tags__ = [\"spark\", \"filter\", \"big data\",\"csv\",\"projectspace\"]\n",
    "    __category__ = \"Spark\"\n",
    "#     __technology__ = razor.Technology.SPARK\n",
    "    \n",
    "    # Atomic input - csv filename relative to project space\n",
    "    ip_data:DataFrame\n",
    "    # Atomic output of type spark DataFrame.\n",
    "    op_path: str\n",
    "    \n",
    "    def run(self):\n",
    "        path = api.datasources(\"Project Space\").abspath()\n",
    "        self.ip_data.write.csv(os.path.join(path, self.op_path),\n",
    "                               header=\"true\", \n",
    "                               mode=\"overwrite\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "known-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_write = SparkWrite(ip_data=random_process.op_data,op_path=\"new_csv.csv\",config={},source=\"\") \n",
    "spark_write.executor = SparkExecutor\n",
    "# following are the data types of inputs\n",
    "# (ip_data -> null)\n",
    "# (op_path -> string)\n",
    "# (config -> dict)\n",
    "# (source -> string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mature-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = rf.Pipeline(targets = [spark_write])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "enabling-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.interactive+pipeline+view+json": {
       "blocks": [
        {
         "class_name": "RandomProcess",
         "fullname": ".RandomProcess",
         "id": "10807f0a-5a69-40c8-9d5c-65814c464540",
         "inputs": [
          {
           "dataType": null,
           "default": null,
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "ip_data",
           "meta": {},
           "name": "ip_data",
           "series": false,
           "type": "DataFrame",
           "type_check": true
          },
          {
           "dataType": "dict",
           "default": {},
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "config",
           "meta": {},
           "name": "config",
           "series": false,
           "type": "dict",
           "type_check": true
          },
          {
           "dataType": "string",
           "default": "",
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "source",
           "meta": {},
           "name": "source",
           "series": false,
           "type": "str",
           "type_check": true
          }
         ],
         "outputs": [
          {
           "flow": "atomic",
           "help": null,
           "label": "op_data",
           "meta": {},
           "name": "op_data",
           "series": false,
           "type": "DataFrame",
           "type_check": true
          }
         ],
         "overwritten": false,
         "published": false,
         "var_names": [
          "RandomProcess"
         ]
        },
        {
         "class_name": "SparkWrite",
         "fullname": ".SparkWrite",
         "id": "743b6b89-763d-4029-ad24-5241a104fa41",
         "inputs": [
          {
           "dataType": null,
           "default": null,
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "ip_data",
           "meta": {},
           "name": "ip_data",
           "series": false,
           "type": "DataFrame",
           "type_check": true
          },
          {
           "dataType": "string",
           "default": "",
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "op_path",
           "meta": {},
           "name": "op_path",
           "series": false,
           "type": "str",
           "type_check": true
          },
          {
           "dataType": "dict",
           "default": {},
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "config",
           "meta": {},
           "name": "config",
           "series": false,
           "type": "dict",
           "type_check": true
          },
          {
           "dataType": "string",
           "default": "",
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "source",
           "meta": {},
           "name": "source",
           "series": false,
           "type": "str",
           "type_check": true
          }
         ],
         "outputs": [],
         "overwritten": false,
         "published": false,
         "var_names": [
          "SparkWrite"
         ]
        },
        {
         "class_name": "ReadCsvProjectSpace",
         "fullname": ".ReadCsvProjectSpace",
         "id": "cec44845-c029-42ea-9851-72926f2c0ff8",
         "inputs": [
          {
           "dataType": "string",
           "default": "",
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "filename",
           "meta": {},
           "name": "filename",
           "series": false,
           "type": "str",
           "type_check": true
          },
          {
           "dataType": "dict",
           "default": {},
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "config",
           "meta": {},
           "name": "config",
           "series": false,
           "type": "dict",
           "type_check": true
          },
          {
           "dataType": "string",
           "default": "",
           "flow": "atomic",
           "help": null,
           "isdict": false,
           "islist": false,
           "label": "source",
           "meta": {},
           "name": "source",
           "series": false,
           "type": "str",
           "type_check": true
          }
         ],
         "outputs": [
          {
           "flow": "atomic",
           "help": null,
           "label": "data",
           "meta": {},
           "name": "data",
           "series": false,
           "type": "DataFrame",
           "type_check": true
          }
         ],
         "overwritten": false,
         "published": false,
         "var_names": [
          "ReadCsvProjectSpace"
         ]
        }
       ],
       "connections": [
        {
         "id": "c4e8aff6-4de3-4570-a9e3-d9cdfd766947",
         "source": {
          "adapter": false,
          "instance_id": "ac549da2-30f7-4cdf-a1cd-38e490f0c0a7",
          "name": "data"
         },
         "target": {
          "adapter": false,
          "instance_id": "99783e08-2bf6-42bd-917f-b2c8df7a61f0",
          "name": "ip_data"
         }
        },
        {
         "id": "87f71096-914d-412c-974c-515ee94505bf",
         "source": {
          "adapter": false,
          "instance_id": "99783e08-2bf6-42bd-917f-b2c8df7a61f0",
          "name": "op_data"
         },
         "target": {
          "adapter": false,
          "instance_id": "a169c44f-abbd-4cc2-8a6e-61e3b3c1a2b3",
          "name": "ip_data"
         }
        }
       ],
       "id": "87ff8857-f8c1-4d46-aff0-e28cd744ddbf",
       "instances": [
        {
         "block_class": "743b6b89-763d-4029-ad24-5241a104fa41",
         "id": "a169c44f-abbd-4cc2-8a6e-61e3b3c1a2b3",
         "name": "SparkWrite_1",
         "var_names": [
          "spark_write"
         ]
        },
        {
         "block_class": "10807f0a-5a69-40c8-9d5c-65814c464540",
         "id": "99783e08-2bf6-42bd-917f-b2c8df7a61f0",
         "name": "RandomProcess_1",
         "var_names": [
          "random_process"
         ]
        },
        {
         "block_class": "cec44845-c029-42ea-9851-72926f2c0ff8",
         "id": "ac549da2-30f7-4cdf-a1cd-38e490f0c0a7",
         "name": "ReadCsvProjectSpace_1",
         "var_names": [
          "read_csv_project_space"
         ]
        }
       ],
       "name": "Pipeline_1",
       "var_names": []
      },
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"306pt\" height=\"210pt\"\n",
       " viewBox=\"0.00 0.00 305.86 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-206 301.86,-206 301.86,4 -4,4\"/>\n",
       "<!-- SparkWrite(&#39;SparkWrite_1&#39;) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>SparkWrite(&#39;SparkWrite_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"148.93\" cy=\"-18\" rx=\"87.92\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.93\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">SparkWrite(&#39;SparkWrite_1&#39;)</text>\n",
       "</g>\n",
       "<!-- RandomProcess(&#39;RandomProcess_1&#39;) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>RandomProcess(&#39;RandomProcess_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"148.93\" cy=\"-101\" rx=\"115.93\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.93\" y=\"-98.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">RandomProcess(&#39;RandomProcess_1&#39;)</text>\n",
       "</g>\n",
       "<!-- RandomProcess(&#39;RandomProcess_1&#39;)&#45;&gt;SparkWrite(&#39;SparkWrite_1&#39;) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>RandomProcess(&#39;RandomProcess_1&#39;)&#45;&gt;SparkWrite(&#39;SparkWrite_1&#39;)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.93,-82.82C148.93,-72.19 148.93,-58.31 148.93,-46.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.43,-46.15 148.93,-36.15 145.43,-46.15 152.43,-46.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"192.93\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">op_data&#45;&gt;ip_data</text>\n",
       "</g>\n",
       "<!-- ReadCsvProjectSpace(&#39;ReadCsvProjectSpace_1&#39;) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ReadCsvProjectSpace(&#39;ReadCsvProjectSpace_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"148.93\" cy=\"-184\" rx=\"148.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.93\" y=\"-181.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">ReadCsvProjectSpace(&#39;ReadCsvProjectSpace_1&#39;)</text>\n",
       "</g>\n",
       "<!-- ReadCsvProjectSpace(&#39;ReadCsvProjectSpace_1&#39;)&#45;&gt;RandomProcess(&#39;RandomProcess_1&#39;) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>ReadCsvProjectSpace(&#39;ReadCsvProjectSpace_1&#39;)&#45;&gt;RandomProcess(&#39;RandomProcess_1&#39;)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.93,-165.82C148.93,-155.19 148.93,-141.31 148.93,-129.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.43,-129.15 148.93,-119.15 145.43,-129.15 152.43,-129.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.93\" y=\"-140\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">data&#45;&gt;ip_data</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<razor.flow.pipeline.Pipeline at 0x7f9a8ef6e090>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cooked-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.run+monitor+json": "/tmp/tmp8es0afy0/Pipeline_1",
      "text/plain": [
       "<razor_tools.backend.ipython.mime.run_monitor.RunMonitor at 0x7f9a8ed62cd0>"
      ]
     },
     "metadata": {
      "application/vnd.razorthink.run+monitor+json": {
       "store_in_notebook": true
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Process(Pipeline Manager('Pipeline_1'), stopped)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
