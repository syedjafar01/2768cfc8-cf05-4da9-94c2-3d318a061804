{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razor import Block, inputs, outputs, Pipeline\n",
    "from razor.api import project_space_path\n",
    "import razor\n",
    "from razor import Technology, LibraryMode\n",
    "from razor.core.blocks import ContainerExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging by concat to not lose dtypes\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1913         # Last day in train set\n",
    "MAIN_INDEX = ['id','d']  # We can identify item by these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Main Data\n"
     ]
    }
   ],
   "source": [
    "########################### Load Data\n",
    "#################################################################################\n",
    "print('Load Main Data')\n",
    "\n",
    "# Here are reafing all our data \n",
    "# without any limitations and dtype modification\n",
    "train_df = pd.read_csv(project_space_path(\"M5Forecasting/sales_train_validation.csv\"))\n",
    "prices_df = pd.read_csv(project_space_path(\"M5Forecasting/sell_prices.csv\"))\n",
    "calendar_df = pd.read_csv(project_space_path(\"M5Forecasting/calendar.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reduce_mem_usage(train_df)\n",
    "prices_df = reduce_mem_usage(prices_df)\n",
    "calendar_df = reduce_mem_usage(calendar_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 1919)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "\t<table width='100%'>\n",
       "\t\t<tr'><th>Slave Host</th><th>Type</th><th colspan='3' style='text-align: center;'>Usage</th></tr>\n",
       "\t\t<tbody>\n",
       "\t\t\t<tr><td>172.16.104.139 </td><td> INFRASTRUCTURE </td><td> CORE: Used 3 of 16 (18.75%)</td><td>RAM: Used 3.0 of 38.0GB (7.894736842105263%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.114.99 </td><td> TECHNOLOGY </td><td> CORE: Used 1 of 32 (3.125%)</td><td>RAM: Used 4.0 of 115.0GB (3.4782608695652173%)</td></tr>\n",
       "\n",
       "\t\t</tbody>\n",
       "\t</table>\n",
       "</html>"
      ],
      "text/plain": [
       "PlatformEngineHealthList(slave_usage_array=[PlatformEngineHealth(server_ip='172.16.104.139', server_type='INFRASTRUCTURE', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=16, used=3, available=13, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=40802189312.0, used=3221225472.0, available=37580963840.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')]), PlatformEngineHealth(server_ip='172.16.114.99', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=32, used=1, available=31, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=123480309760.0, used=4294967296.0, available=119185342464.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines(\"DS-engine\").health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(project_space_path('train_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/project-space/train_df.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_space_path('train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inputs.atomic.string('path')\n",
    "class Melter(Block):\n",
    "    def run(self, path):\n",
    "        import logging\n",
    "        from razor.api import project_space_path\n",
    "        import pandas as pd\n",
    "        \n",
    "        TARGET = 'sales'\n",
    "        df = pd.read_csv(project_space_path(path))\n",
    "        logging.info('Create Grid')\n",
    "        index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "        grid_df = pd.melt(df, \n",
    "                          id_vars = index_columns, \n",
    "                          var_name = 'd', \n",
    "                          value_name = TARGET)\n",
    "        \n",
    "        logging.info(grid_df.head())\n",
    "        grid_df.to_csv(project_space_path('melted_df.csv'), index=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "melter = (\n",
    "    Melter()\n",
    "    .path('train_df.csv')  # (series, string)\n",
    "    .executor(ContainerExecutor(cores=2, memory=8192))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline(\"Melting\", targets=[melter], env=Technology.PYTHON)  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.interactive+pipeline+view+json": {
       "blocks": [
        {
         "class_name": "Melter",
         "id": "4f9f5316-efd9-4a84-8fdb-554ab24d1f65",
         "inputs": [
          {
           "default": "",
           "doc": null,
           "dtype": "string",
           "flow": "series",
           "label": null,
           "name": "path",
           "required": false
          }
         ],
         "outputs": [],
         "overwritten": false,
         "var_names": [
          "Melter"
         ]
        }
       ],
       "connections": [],
       "id": "f727599a-f75a-4b71-a608-028af7723f6e",
       "instances": [
        {
         "block_class": "4f9f5316-efd9-4a84-8fdb-554ab24d1f65",
         "id": "87759e17-feae-48c3-ae9a-2824348e3d33",
         "name": "Melter_1",
         "var_names": [
          "melter"
         ]
        }
       ],
       "name": "Melting",
       "var_names": []
      },
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"126pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 125.73 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 121.7326,-40 121.7326,4 -4,4\"/>\n",
       "<!-- (Melter) Melter_1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>(Melter) Melter_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"58.8663\" cy=\"-18\" rx=\"58.7329\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.8663\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#000000\">(Melter) Melter_1</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<razor.core.pipeline.pipeline.Pipeline at 0x7ff4d89fd650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "                    <h5>Pipeline: Melting <span style='float:right; color:orange'>Running<span></h5>\n",
       "                    <h5>Description: </h5>\n",
       "                    <h5>Comments: </h5>\n",
       "\n",
       "                    <table width='100%'>\n",
       "                        <tr>\n",
       "                            <th style='text-align:left;'>Run number</th>\n",
       "                            <th style='text-align:left;'>Version</th>\n",
       "                            <th style='text-align:left;'>Run at</th>\n",
       "                            <th style='text-align:left;'>Wait time</th>\n",
       "                            <th style='text-align:left;'>Compute time</th>\n",
       "                            <th style='text-align:left;'>Run by</th>\n",
       "                            <th style='text-align:left;'>Source</th>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style='text-align:left;'>8</td>\n",
       "                            <td style='text-align:left;'>None</td>\n",
       "                            <td style='text-align:left;'>Jul 28, 2020 09:15AM</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>Ayan Basak</td>\n",
       "                            <td style='text-align:left;'>Jupyter</td>\n",
       "                        </tr>\n",
       "                    </table><h5>Pipeline-level Resource Spec: NA</h5><h5>Blocks: </h5>\n",
       "\n",
       "                  <table width='100%'>\n",
       "                      <tr>\n",
       "                          <th style='text-align:left;'>Block</th>\n",
       "                          <th style='text-align:left;'>Status</th>\n",
       "                          <th style='text-align:left;'>Technology</th>\n",
       "                          <th style='text-align:left;'>Wait time</th>\n",
       "                          <th style='text-align:left;'>Compute time</th>\n",
       "                          <th style='text-align:left;'>Resource spec</th>\n",
       "                      </tr>\n",
       "                <tr>\n",
       "                            <td style='text-align:left;'>Melter_1</td>\n",
       "                            <td style='text-align:left; color: rgba(87, 101, 255, 1)'>Queued</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>2s</td>\n",
       "                            <td style='text-align:left;'>0s</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 8192,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"additional_resource_spec\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    </table>\n",
       "                </html>"
      ],
      "text/plain": [
       "PlatformPipelineRun(project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', pipeline_id='d18dd812-d0b2-11ea-bc5a-55ff63d3667a', pipeline_name='Melting', pipeline_run_id='e5de69cb-a742-4f15-a17e-4492e34fed52', pipeline_version=None, comment=None, created_on='2020-07-28T09:15:07.800+0000', start_time=None, end_time=None, eta=0, run_at=1595927707800, run_duration=0, compute_time=0, wait_time=0, ran_by_user=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), status='IN_PROGRESS', block_status=[PlatformPipelineBlockRun(pipeline_run_id='e5de69cb-a742-4f15-a17e-4492e34fed52', pipeline_name='Melting', pipeline_status='IN_PROGRESS', block_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', block_run_id='83a6cd71-cfb5-4f04-a138-e1a1cfeca511', block_name='Melter_1', resource_spec=ResourceAllocated(cores=2, memory=8192, use_gpu=False, gpu=0, use_gpu_if_available=False, additional_resource_spec={}, run_env='PYTHON'), technology='PYTHON', wait_time=0, compute_time=0, status='YET_TO_START', containers=[], cluster_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', _log=None, _metric=None)], run_number=8, pipeline_variable_list=[], block_run_details=[BlockRunDetail(block_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', block_run_id='83a6cd71-cfb5-4f04-a138-e1a1cfeca511', block_name='Melter_1', technology='PYTHON', log_path=None, input_parameters='{\\n  \"path\": {\\n    \"dtype\": \"string\",\\n    \"required\": \"false\",\\n    \"series\": false,\\n    \"adapter\": \"eJxrYJlqzAABPRJFiVX5RXrJ+UWpekk5+cnZxXqZeQWlJcVTeoScQHxPEE8vMSWxoCS1aMrkKXoAUvYVmA==\",\\n    \"validator\": \"eJxrYJnqyAABPRJFiVX5RXrJ+UWpekk5+cnZxXqZeQWlJcVTehQcS/JzM5OdQKLBJUWZeemeIBm9ssSczJTEkvyiKZOn6AEArzAbbQ==\",\\n    \"source_id\": null,\\n    \"source_name\": null,\\n    \"inferred_type\": \"STATIC\",\\n    \"value\": \"eJxrYJkqwAABPTwlRYmZefEpaXrJxWVT9ABRyQdF\"\\n  }\\n}', output_parameters=None, status='YET_TO_START', created_at=None, start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[], resource_allocated=ResourceAllocated(cores=2, memory=8192, use_gpu=False, gpu=0, use_gpu_if_available=False, additional_resource_spec={}, run_env='PYTHON'))], pipeline_json='{\\n  \"id\": \"d18dd812-d0b2-11ea-bc5a-55ff63d3667a\",\\n  \"projectId\": \"c0b26d85-a4c9-44f5-9d0e-f540dd2de644\",\\n  \"name\": \"Melting\",\\n  \"description\": \"\",\\n  \"blocks\": [\\n    {\\n      \"name\": \"Melter_1\",\\n      \"id\": \"390773c5-a83c-44ef-a0e6-c247287fb8ef\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"Melter\",\\n      \"code\": \"eJxtU0tvGzcQXq72ZTlWiiKPtofCR+dgIXFkRwGaAqlQBK1QHRy3t4KgdrjatajlZsl14mJVFAiCIABzKnu3/0n/WTtcKUgOWQGaIefBeXzfX8E//wZe95m7qZANVEW6FHz4iW7N17Tm+SXUTHOqllxwLUuaCqaU/dse5J65RVds+TmbSeZNIXRRKmsCfVlxvDTRL1xoXlvzVc3+kPUwlTUfzoVMl2orrAl/cAp6v7Fra2JKQaaU2pky+/dHDx+PxvxkPErvj4DxMYP5iJ2MHxxlR4/hKLMzbU8x6sD0KV1JaATHSJPggRWlU3t1U1ose0CzQgiaNWWqC1lum7n5sZnOhNd4u0e3ndAPbSQTCfzMHd7gewdTf+pNd6bRdDL5Ewh4wlv7KH1BVv66R7zurrcOoLcO2+AqaHsteU2uyTpq/asQgmuCPiFEEEMCO9BfROu4Dc6jNmpj2G1DuPE+WCfOt02u4mvP+bfJedL2YO81gQHcfO9jBu+5Zw9mU898WdXynKeaqoqlnFZM51ioCRUTHAe8O6k57nP/WV2ANb77iwvNV7TTgFe606KUbZREaVzTB9UhwamkCwN6wWrMmaCgJVshZPoXTDR8c3hrzd7KrRwoZMNUXdh3JixK4K+wII17ioVcLIpyYc3OBhGsKmy+b6KKlcBcYqwVqIs0QVFmEoVLiCJHA1apZWd1yQLFRYaWruH8IabxK+dy9vT02Y9n2Cqgda97nqZSNCuHzXiBY8DqMIP59ruiutS5LA+Lsmr04ejwUQaj45NHx+Oj8fH3Nr897U2+8UhCbpDED8iA9MkXJCI+/hJ/QOy9ew6AP/+Hn0PhLsXhp0u2cDCcORy6qaCe32rebpEaL4ScM6Ec2BPgGWuEVugcQJFqdzlAQqoGF9DN1ZmiDbQxiwm6Mee3TQ9Zgqa79BP6UtXMN67K/o57Z2UpcX+I981rLxomtjvb8HLo2GH6y5cf62j0KdKiG4eiW4nB+ROsPf81f2JC6FjxOUZvvc2dp1quirTj9XNd47p/chbHpFCwORd2lv82c9DrXrXG6/b+oilqDvZdo8wd2gW7AhCBJYI6lU2p7ZRgfcP/AZ3Iwt0=\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {\\n        \"path\": {\\n          \"dtype\": \"string\",\\n          \"required\": \"false\",\\n          \"series\": false,\\n          \"adapter\": \"eJxrYJlqzAABPRJFiVX5RXrJ+UWpekk5+cnZxXqZeQWlJcVTeoScQHxPEE8vMSWxoCS1aMrkKXoAUvYVmA==\",\\n          \"validator\": \"eJxrYJnqyAABPRJFiVX5RXrJ+UWpekk5+cnZxXqZeQWlJcVTehQcS/JzM5OdQKLBJUWZeemeIBm9ssSczJTEkvyiKZOn6AEArzAbbQ==\",\\n          \"source_id\": null,\\n          \"source_name\": null,\\n          \"inferred_type\": \"STATIC\",\\n          \"value\": \"eJxrYJkqwAABPTwlRYmZefEpaXrJxWVT9ABRyQdF\"\\n        }\\n      },\\n      \"outputProperty\": {},\\n      \"resourceRequirement\": {\\n        \"cores\": 2,\\n        \"memory\": 8192,\\n        \"useGpu\": false,\\n        \"gpu\": 0,\\n        \"useGpuIfAvailable\": false,\\n        \"runEnv\": \"PYTHON\",\\n        \"additionalResourceSpec\": {}\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"eta\": 0\\n    }\\n  ],\\n  \"connections\": [],\\n  \"priority\": \"LOW\",\\n  \"infraResourceEstimation\": null,\\n  \"resourceRequirement\": {},\\n  \"comments\": null,\\n  \"order\": null,\\n  \"uiData\": null,\\n  \"dom\": null,\\n  \"systemGenerated\": false,\\n  \"systemModel\": false,\\n  \"pipelineVariableList\": [],\\n  \"pipelineTemplateVersion\": 0.0,\\n  \"versionId\": null,\\n  \"engineId\": \"65ed2499-f8c9-4c4d-ad27-aa689bd1531e\",\\n  \"userId\": \"c4080201-ccc9-4657-a457-7e18c100ff28\",\\n  \"runInitiatedFrom\": \"JUPYTER\"\\n}', dom='Yet to add', order=None, infra_resource='{\\n  \"zookeeper\": {\\n    \"cores\": 1,\\n    \"memory\":  1024\\n  },\\n  \"kafka\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"additionalResourceSpec\":{}\\n  }\\n}', resource_spec={}, engine_id='65ed2499-f8c9-4c4d-ad27-aa689bd1531e', run_initiated_from='JUPYTER')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><pre>------------------------------------------------\n",
       "|                   BLOCK LOGS                 |\n",
       "------------------------------------------------\n",
       "*** Block: Melter_1 ***\n",
       "\n",
       " 2020-07-28 09:15:15.766: Block is ready to run 140109229309296\n",
       " 2020-07-28 09:15:19.627: Setting block parameters\n",
       " 2020-07-28 09:15:19.633: Output status of block(83a6cd71-cfb5-4f04-a138-e1a1cfeca511) for output_dent(None) is: COMPLETED and Output: None\n",
       "------------------------------------------------\n",
       "</pre></body></html>"
      ],
      "text/plain": [
       "PlatformPipelineRunLogs(pipeline_name='Melting', engine_logs=[], block_logs=[PlatformPipelineBlockRunLogs(pipeline_id='d18dd812-d0b2-11ea-bc5a-55ff63d3667a', pipeline_run_id='e5de69cb-a742-4f15-a17e-4492e34fed52', block_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', block_run_id='83a6cd71-cfb5-4f04-a138-e1a1cfeca511', logs=[PlatformPipelineBlockRunLog(log_level='DEBUG', log_type='Block', timestamp='2020-07-28 09:15:15.766', message='Block is ready to run 140109229309296', pipeline_id='d18dd812-d0b2-11ea-bc5a-55ff63d3667a', pipeline_run_id='e5de69cb-a742-4f15-a17e-4492e34fed52', block_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', block_run_id='83a6cd71-cfb5-4f04-a138-e1a1cfeca511', pipeline_name='Melting', block_name='Melter_1'), PlatformPipelineBlockRunLog(log_level='INFO', log_type='Block', timestamp='2020-07-28 09:15:19.627', message='Setting block parameters', pipeline_id='d18dd812-d0b2-11ea-bc5a-55ff63d3667a', pipeline_run_id='e5de69cb-a742-4f15-a17e-4492e34fed52', block_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', block_run_id='83a6cd71-cfb5-4f04-a138-e1a1cfeca511', pipeline_name='Melting', block_name='Melter_1'), PlatformPipelineBlockRunLog(log_level='DEBUG', log_type='Block', timestamp='2020-07-28 09:15:19.633', message='Output status of block(83a6cd71-cfb5-4f04-a138-e1a1cfeca511) for output_dent(None) is: COMPLETED and Output: None', pipeline_id='d18dd812-d0b2-11ea-bc5a-55ff63d3667a', pipeline_run_id='e5de69cb-a742-4f15-a17e-4492e34fed52', block_id='390773c5-a83c-44ef-a0e6-c247287fb8ef', block_run_id='83a6cd71-cfb5-4f04-a138-e1a1cfeca511', pipeline_name='Melting', block_name='Melter_1')], pipeline_name='Melting', block_name='Melter_1')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Grid\n",
      "Train rows: 30490 191300\n"
     ]
    }
   ],
   "source": [
    "print('Create Grid')\n",
    "\n",
    "# We can tranform horizontal representation \n",
    "# to vertical \"view\"\n",
    "# Our \"index\" will be 'id','item_id','dept_id','cat_id','store_id','state_id'\n",
    "# and labels are 'd_' coulmns\n",
    "\n",
    "index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "grid_df = pd.melt(train_df.iloc[:100, :], \n",
    "                  id_vars = index_columns, \n",
    "                  var_name = 'd', \n",
    "                  value_name = TARGET)\n",
    "\n",
    "# If we look on train_df we se that \n",
    "# we don't have a lot of traning rows\n",
    "# but each day can provide more train data\n",
    "print('Train rows:', len(train_df), len(grid_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Grid\n"
     ]
    }
   ],
   "source": [
    "# To be able to make predictions\n",
    "# we need to add \"test set\" to our grid\n",
    "add_grid = pd.DataFrame()\n",
    "for i in range(1,29):\n",
    "    temp_df = train_df[index_columns]\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n",
    "    temp_df[TARGET] = np.nan\n",
    "    add_grid = pd.concat([add_grid,temp_df])\n",
    "\n",
    "grid_df = pd.concat([grid_df,add_grid])\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# Remove some temoprary DFs\n",
    "del temp_df, add_grid\n",
    "\n",
    "# We will not need original train_df\n",
    "# anymore and can remove it\n",
    "del train_df\n",
    "\n",
    "# You don't have to use df = df construction\n",
    "# you can use inplace=True instead.\n",
    "# like this\n",
    "# grid_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Let's check our memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# We can free some memory \n",
    "# by converting \"strings\" to categorical\n",
    "# it will not affect merging and \n",
    "# we will not lose any valuable data\n",
    "for col in index_columns:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# Let's check again memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
