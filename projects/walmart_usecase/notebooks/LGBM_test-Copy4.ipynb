{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "            <h4>Library</h4>\n",
       "            <table width='100%'>\n",
       "                <tr>\n",
       "                    <th width='20%' style='align:left; text-align:center;'>Name</th>\n",
       "                    <th style='align:left; text-align:left;'>Technology</th>\n",
       "                    <th style='align:left; text-align:left;'>Install Status</th>\n",
       "                    <th style='align:left; text-align:left;'>Created by</th>\n",
       "                    <th style='align:left; text-align:left;'>Created on</th>\n",
       "                    <th style='align:left; text-align:left;'>Modified by</th>\n",
       "                    <th style='align:left; text-align:left;'>Modified on</th>\n",
       "                </tr><tr>\n",
       "                        <td width='20%' style='align:center; text-align:center;'>fastparquet</td>\n",
       "                        <td style='align:left; text-align:left;'>PYTHON</td>\n",
       "                        <td style='align:left; text-align:left;'>INSTALLED</td>\n",
       "                        <td style='align:left; text-align:left;'>Ayan Basak</td>\n",
       "                        <td style='align:left; text-align:left;'>Sep 25, 2020</td>\n",
       "                        <td style='align:left; text-align:left;'>Ayan Basak</td>\n",
       "                        <td style='align:left; text-align:left;'>Sep 25, 2020</td>\n",
       "                    </tr></table></html>"
      ],
      "text/plain": [
       "PlatformLibrary(id_='54865fdd-700e-494b-a8f8-0b6258aed7cf', artifact_version='01a8b174-7b78-4a53-bf28-5938922e4cd8', name='fastparquet', technology='PYTHON', installation_status='INSTALLED', created_by='Ayan Basak', created_on='2020-09-25T12:27:54.000+00:00', modified_by='Ayan Basak', modified_on='2020-09-25T12:27:54.000+00:00')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.libraries('fastparquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'cpu': 8 , 'ram': 36000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor.flow as rf\n",
    "from razor.api import datasources\n",
    "from razor import project_space_path\n",
    "import razor\n",
    "from razor import Technology, LibraryMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = razor.api.libraries(name='lightgbm').artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=config['cpu'], memory=config['ram'], gpu=1))\n",
    "class Infer:\n",
    "#     config: t.Any\n",
    "    \n",
    "    __libs__ = [lib1]\n",
    "    \n",
    "    def init(self):\n",
    "        self.VER = 1                          # Our model version\n",
    "        self.SEED = 42  \n",
    "        \n",
    "        #PATHS for Features\n",
    "        self.ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "        self.BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1.pkl')\n",
    "        self.PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "        self.CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "        self.LAGS     = project_space_path('M5Forecasting/lags_df_28.pkl')\n",
    "        self.MEAN_ENC = project_space_path('M5Forecasting/mean_encoding_df.pkl')\n",
    "\n",
    "        #LIMITS and const\n",
    "        self.TARGET      = 'sales'            # Our target\n",
    "        self.START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "        self.END_TRAIN   = 1913               # End day of our train set\n",
    "        self.P_HORIZON   = 28                 # Prediction horizon\n",
    "        self.USE_AUX     = False               # Use or not pretrained models\n",
    "        self.N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "        # AUX(pretrained) Models paths\n",
    "        self.AUX_MODELS = './M5Forecasting/m5-aux-models/'\n",
    "\n",
    "\n",
    "        #STORES ids\n",
    "        self.STORES_IDS = pd.read_csv(self.ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "        self.STORES_IDS = list(self.STORES_IDS.unique())\n",
    "\n",
    "\n",
    "        #SPLITS for lags creation\n",
    "        self.SHIFT_DAY  = 28\n",
    "        self.N_LAGS     = 15\n",
    "        self.LAGS_SPLIT = [col for col in range(self.SHIFT_DAY, self.SHIFT_DAY + self.N_LAGS)]\n",
    "        \n",
    "        self.remove_features = ['id','state_id','store_id',\n",
    "                           'date','wm_yr_wk','d', self.TARGET]\n",
    "        self.mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                           'enc_dept_id_mean','enc_dept_id_std',\n",
    "                           'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "            \n",
    "    def seed_everything(self, seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    ## Multiprocess Runs\n",
    "    def df_parallelize_run(self, func, t_split):\n",
    "        num_cores = np.min([self.N_CORES,len(t_split)])\n",
    "        pool = Pool(num_cores)\n",
    "        df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "\n",
    "    def get_data_by_store(self, store):\n",
    "\n",
    "        # Read and contact basic feature\n",
    "        df1 = pd.read_pickle(self.BASE)\n",
    "#         df1 = df1[df1['store_id']==store]\n",
    "        df2 = pd.read_pickle(self.PRICE).iloc[:,2:]\n",
    "#         df2 = df2[df2['store_id']==store]\n",
    "        df3 = pd.read_pickle(self.CALENDAR).iloc[:,2:]\n",
    "        df = pd.concat([df1, df2, df3],\n",
    "                        axis=1)\n",
    "\n",
    "        # Leave only relevant store\n",
    "        df = df[df['store_id']==store]\n",
    "\n",
    "        # With memory limits we have to read \n",
    "        # lags and mean encoding features\n",
    "        # separately and drop items that we don't need.\n",
    "        # As our Features Grids are aligned \n",
    "        # we can use index to keep only necessary rows\n",
    "        # Alignment is good for us as concat uses less memory than merge.\n",
    "        df2 = pd.read_pickle(self.MEAN_ENC)[self.mean_features]\n",
    "        df2 = df2[df2.index.isin(df.index)]\n",
    "\n",
    "        df = pd.concat([df, df2], axis=1)\n",
    "        del df2 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        df3 = pd.read_pickle(self.LAGS).iloc[:,3:]\n",
    "        df3 = df3[df3.index.isin(df.index)]\n",
    "\n",
    "\n",
    "        df = pd.concat([df, df3], axis=1)\n",
    "        del df3 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        # Create features list\n",
    "        features = [col for col in list(df) if col not in self.remove_features]\n",
    "        features = [col for col in features if col not in ['Unnamed: 0']]\n",
    "        \n",
    "        del df # to not reach memory limit \n",
    "        gc.collect()\n",
    "        \n",
    "        return features\n",
    "\n",
    "    # Recombine Test set after training\n",
    "    def get_base_test(self):\n",
    "        base_test = pd.DataFrame()\n",
    "\n",
    "        for store_id in self.STORES_IDS:\n",
    "            temp_df = pd.read_pickle(project_space_path('M5Forecasting/test_'+store_id+'.pkl'))\n",
    "            temp_df['store_id'] = store_id\n",
    "            base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "\n",
    "        return base_test\n",
    "\n",
    "\n",
    "    ########################### Helper to make dynamic rolling lags\n",
    "    #################################################################################\n",
    "    def make_lag(self, LAG_DAY):\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'sales_lag_{str(LAG_DAY)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "        return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "    def make_lag_roll(self, LAG_DAY, base_test):\n",
    "        shift_day = LAG_DAY[0]\n",
    "        roll_wind = LAG_DAY[1]\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'rolling_mean_tmp_{str(shift_day)}_{str(roll_wind)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "        return lag_df[[col_name]]\n",
    "    \n",
    "    def run(self):\n",
    "        ########################### Predict\n",
    "        #################################################################################\n",
    "\n",
    "        # Create Dummy DataFrame to store predictions\n",
    "        all_preds = pd.DataFrame()\n",
    "\n",
    "        # Join back the Test dataset with \n",
    "        # a small part of the training data \n",
    "        # to make recursive features\n",
    "        base_test = self.get_base_test()\n",
    "\n",
    "        # Timer to measure predictions time \n",
    "        main_time = time.time()\n",
    "\n",
    "        ROLS_SPLIT = []\n",
    "\n",
    "        for i in [1,7,14]:\n",
    "            for j in [7,14,30,60]:\n",
    "                ROLS_SPLIT.append([i,j])\n",
    "        \n",
    "        # Make temporary grid to calculate rolling lags\n",
    "        grid_df = base_test.copy()\n",
    "        lag_param_df = pd.DataFrame()\n",
    "#             grid_df = pd.concat([grid_df, self.df_parallelize_run(self.make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "        for lag_param in ROLS_SPLIT:\n",
    "            lag_param_df = pd.concat([lag_param_df, self.make_lag_roll(lag_param,base_test)], axis=1)\n",
    "        grid_df = pd.concat([grid_df, lag_param_df], axis=1)\n",
    "\n",
    "\n",
    "        # Loop over each prediction day\n",
    "        # As rolling lags are the most timeconsuming\n",
    "        # we will calculate it for whole day\n",
    "        for PREDICT_DAY in range(1,29):    \n",
    "            print('Predict | Day:', PREDICT_DAY)\n",
    "            start_time = time.time()\n",
    "\n",
    "            for store_id in self.STORES_IDS:\n",
    "                self.logger.info(store_id)\n",
    "\n",
    "                # Read all our models and make predictions\n",
    "                # for each day/store pairs\n",
    "                model_path = project_space_path('M5Forecasting/lgb_model_'+store_id+'_v'+str(self.VER)+'.bin') \n",
    "                if self.USE_AUX:\n",
    "                    model_path = self.AUX_MODELS + model_path\n",
    "\n",
    "                estimator = pickle.load(open(model_path, 'rb'))\n",
    "\n",
    "                day_mask = base_test['d']==(self.END_TRAIN+ PREDICT_DAY)\n",
    "                store_mask = base_test['store_id']==store_id\n",
    "\n",
    "                mask = (day_mask)&(store_mask)\n",
    "                MODEL_FEATURES = self.get_data_by_store(store_id)\n",
    "                base_test[self.TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "\n",
    "            # Make good column naming and add \n",
    "            # to all_preds DataFrame\n",
    "            temp_df = base_test[day_mask][['id',self.TARGET]]\n",
    "            temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "            if 'id' in list(all_preds):\n",
    "                all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "            else:\n",
    "                all_preds = temp_df.copy()\n",
    "\n",
    "            print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                          ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                          ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "            del temp_df\n",
    "\n",
    "        all_preds = all_preds.reset_index(drop=True)\n",
    "\n",
    "        submission = pd.read_csv(self.ORIGINAL+'sample_submission_accuracy.csv')[['id']]\n",
    "        submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "        submission.to_csv(self.ORIGINAL+'submission_v'+str(self.VER)+'.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = Infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rf.Pipeline(\"Walmart Inference Pipeline_cpu\", targets=[infer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_pipeline = razor.api.engines('DS-Engine-Load-Test').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.run+monitor+json": "/home/jovyan/logs/f20f0576-930c-4b78-8a69-b4814f18ca14",
      "text/plain": [
       "<razor_tools.backend.ipython.mime.run_monitor.RunMonitor at 0x7fc34f487790>"
      ]
     },
     "metadata": {
      "application/vnd.razorthink.run+monitor+json": {
       "store_in_notebook": false
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "PlatformPipelineRun(project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', pipeline_id='d094e672-0f6d-11eb-8f95-0242ac110008', pipeline_name='Walmart Inference Pipeline_cpu', pipeline_run_id='f20f0576-930c-4b78-8a69-b4814f18ca14', pipeline_version=None, comment=None, created_on='2020-10-16T05:09:49.297+00:00', start_time=None, end_time=None, eta=0, run_at=1602824989297, run_duration=0, compute_time=0, wait_time=-384, ran_by_user=RanByUser(user_name='souryadipta das', email='souryadipta.das@razorthink.com'), status='IN_PROGRESS', block_status=[PlatformPipelineBlockRun(pipeline_run_id='f20f0576-930c-4b78-8a69-b4814f18ca14', pipeline_name='Walmart Inference Pipeline_cpu', pipeline_status='IN_PROGRESS', block_id='6b50eba4-6d31-40a8-b94a-5a200c5f6875', block_run_id='3732f67c-7ff6-42b7-830b-90118d600c73', block_name='Infer_1', resource_spec=ResourceAllocated(cores=8, memory=36000, use_gpu=True, gpu=1, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'), technology='PYTHON', status='READY_TO_GO', containers=[], cluster_id='6b50eba4-6d31-40a8-b94a-5a200c5f6875', _log=None, _metric=None, wait_time=0, compute_time=0, start_time=None, end_time=None, queued_at='2020-10-16T05:09:50.000+00:00')], run_number=360, pipeline_variable_list=[], block_run_details=[BlockRunDetail(block_id='6b50eba4-6d31-40a8-b94a-5a200c5f6875', block_run_id='3732f67c-7ff6-42b7-830b-90118d600c73', block_name='Infer_1', technology='PYTHON', log_path=None, input_parameters='{}', output_parameters=None, status='READY_TO_GO', created_at='2020-10-16T05:09:49.396+00:00', queued_at='2020-10-16T05:09:50.000+00:00', start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[], resource_allocated=ResourceAllocated(cores=8, memory=36000, use_gpu=True, gpu=1, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))], pipeline_json='{\\n  \"id\": \"d094e672-0f6d-11eb-8f95-0242ac110008\",\\n  \"projectId\": \"c0b26d85-a4c9-44f5-9d0e-f540dd2de644\",\\n  \"name\": \"Walmart Inference Pipeline_cpu\",\\n  \"description\": \"\",\\n  \"blocks\": [\\n    {\\n      \"name\": \"Infer_1\",\\n      \"id\": \"6b50eba4-6d31-40a8-b94a-5a200c5f6875\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"Infer\",\\n      \"code\": \"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\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {},\\n      \"outputProperty\": {},\\n      \"resourceRequirement\": {\\n        \"cores\": 8,\\n        \"memory\": 36000,\\n        \"useGpu\": true,\\n        \"gpu\": 1,\\n        \"useGpuIfAvailable\": false,\\n        \"clusterConfiguration\": {\\n          \"worker\": null,\\n          \"workerCore\": null,\\n          \"workerMemory\": null,\\n          \"numberOfInstances\": null,\\n          \"maxServerCount\": null\\n        },\\n        \"additionalEnv\": {},\\n        \"runEnv\": \"PYTHON\"\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [\\n        {\\n          \"libraryId\": \"24d05fb2-8916-4d25-8127-276e57d0bc8d\",\\n          \"libraryVersionId\": \"67ceac05-426d-4c9a-a069-ceb1350c1623\"\\n        },\\n        {\\n          \"libraryId\": \"24d05fb2-8916-4d25-8127-276e57d0bc8d\",\\n          \"libraryVersionId\": \"67ceac05-426d-4c9a-a069-ceb1350c1623\"\\n        }\\n      ],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"process_id\": null,\\n      \"eta\": 0\\n    }\\n  ],\\n  \"connections\": [],\\n  \"priority\": \"LOW\",\\n  \"infraResourceEstimation\": null,\\n  \"resourceRequirement\": {\\n    \"cores\": null,\\n    \"memory\": null,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"comments\": null,\\n  \"order\": null,\\n  \"uiData\": null,\\n  \"dom\": null,\\n  \"systemGenerated\": false,\\n  \"systemModel\": false,\\n  \"pipelineVariableList\": [],\\n  \"pipelineTemplateVersion\": 0.0,\\n  \"versionId\": null,\\n  \"engineId\": \"a723b377-09ff-4869-bc03-e2690d149522\",\\n  \"userId\": \"5da82833-9f26-45a6-b329-19ce45acfb70\",\\n  \"runInitiatedFrom\": \"JUPYTER\",\\n  \"processList\": null,\\n  \"processInfo\": null\\n}', dom='Yet to add', order=None, infra_resource='{\\n  \"zookeeper\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"kafka\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  }\\n}', resource_spec=ResourceAllocated(cores=None, memory=None, use_gpu=None, gpu=None, use_gpu_if_available=None, cluster_configuration=None, additional_env={}, run_env=None), engine_id='a723b377-09ff-4869-bc03-e2690d149522', run_initiated_from='JUPYTER')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "\t<table width='100%'>\n",
       "\t\t<tr'><th>Slave Host</th><th>Type</th><th colspan='3' style='text-align: center;'>Usage</th></tr>\n",
       "\t\t<tbody>\n",
       "\t\t\t<tr><td>172.16.100.119 </td><td> INFRASTRUCTURE </td><td> CORE: Used 0 of 24 (0.0%)</td><td>RAM: Used 0.0 of 76.0GB (0.0%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.105.174 </td><td> TECHNOLOGY </td><td> CORE: Used 0 of 12 (0.0%)</td><td>RAM: Used 0.0 of 47.0GB (0.0%)</td><td>GPU: Used 0 of 1 (0.0%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.121.8 </td><td> TECHNOLOGY </td><td> CORE: Used 32 of 32 (100.0%)</td><td>RAM: Used 109.8828125 of 115.0GB (95.55027173913044%)</td></tr>\n",
       "\n",
       "\t\t</tbody>\n",
       "\t</table>\n",
       "</html>"
      ],
      "text/plain": [
       "PlatformEngineHealthList(slave_usage_array=[PlatformEngineHealth(server_ip='172.16.105.174', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=12, used=0, available=12, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=50465865728.0, used=0.0, available=50465865728.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=1, used=0, available=1, value='GPU')]), PlatformEngineHealth(server_ip='172.16.121.8', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=32, used=32, available=0, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=123480309760.0, used=117985771520.0, available=5494538240.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')]), PlatformEngineHealth(server_ip='172.16.100.119', server_type='INFRASTRUCTURE', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=24, used=0, available=24, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=81604378624.0, used=0.0, available=81604378624.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-Engine-Load-Test').health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <html>\n",
       "            <body>\n",
       "                <h4>Engine Queue</h4>\n",
       "                <h4>Number of queued blocks: 3</h4>\n",
       "                <table width='100%'>\n",
       "                <tr>\n",
       "                    <th style='align:left; text-align:left;'>Block</th>\n",
       "                    <th style='align:left; text-align:left;'>Pipeline</th>\n",
       "                    <th style='align:left; text-align:left;'>Wait Time(hours:minutes:seconds)</th>\n",
       "                </tr>\n",
       "        \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>performance_read</td>\n",
       "                    <td style='align:left; text-align:left;'>Pipeline_26</td>\n",
       "                    <td style='align:left; text-align:left;'>12:49:40</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>performance_read</td>\n",
       "                    <td style='align:left; text-align:left;'>Pipeline_39</td>\n",
       "                    <td style='align:left; text-align:left;'>12:49:25</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>Infer_1</td>\n",
       "                    <td style='align:left; text-align:left;'>Walmart Inference Pipeline_cpu</td>\n",
       "                    <td style='align:left; text-align:left;'>0:00:07</td>\n",
       "                </tr>\n",
       "            \n",
       "                </table>\n",
       "            </body>\n",
       "        </html>\n",
       "        "
      ],
      "text/plain": [
       "PlatformQueueStatusList(queue_list=[PlatformQueueStatus(block_run_id='d56a94c8-db3c-48a7-8e44-f813621efb53', block_id='747374e8-ecb5-4115-809f-46dc66b12c11', block_name='performance_read', pipeline_run_id='0008aa85-a403-40fa-8e84-e264bb7240fc', pipeline_id='4e3364b2-0f02-11eb-8497-0242ac110004', pipeline_name='Pipeline_26', project_id='71e127b9-c19f-41e0-bb54-c9d98d160fe1', wait_time=46180, published_by=RanByUser(user_name='Aneesh K', email='aneesh.k@razorthink.com'), resource_spec=ResourceAllocated(cores=2, memory=2048, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': 1, 'workerCore': 19, 'workerMemory': 71680, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={'SPARK_EXECUTOR_INSTANCES': '1', 'SPARK_EXECUTOR_CORES': '19', 'SPARK_EXECUTOR_MEMORY': '70g'}, run_env='PY_SPARK')), PlatformQueueStatus(block_run_id='30b12e1c-7728-4fb8-a504-89527b4fc371', block_id='ab192175-ae90-4920-8c4b-1513910bc086', block_name='performance_read', pipeline_run_id='899eb3e3-ca00-41a1-8582-423f6172b245', pipeline_id='57a076fc-0f02-11eb-8497-0242ac110004', pipeline_name='Pipeline_39', project_id='71e127b9-c19f-41e0-bb54-c9d98d160fe1', wait_time=46165, published_by=RanByUser(user_name='Aneesh K', email='aneesh.k@razorthink.com'), resource_spec=ResourceAllocated(cores=3, memory=3072, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': 1, 'workerCore': 18, 'workerMemory': 81920, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={'SPARK_EXECUTOR_INSTANCES': '1', 'SPARK_EXECUTOR_CORES': '18', 'SPARK_EXECUTOR_MEMORY': '80g'}, run_env='PY_SPARK')), PlatformQueueStatus(block_run_id='3732f67c-7ff6-42b7-830b-90118d600c73', block_id='6b50eba4-6d31-40a8-b94a-5a200c5f6875', block_name='Infer_1', pipeline_run_id='f20f0576-930c-4b78-8a69-b4814f18ca14', pipeline_id='d094e672-0f6d-11eb-8f95-0242ac110008', pipeline_name='Walmart Inference Pipeline_cpu', project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', wait_time=7, published_by=RanByUser(user_name='souryadipta das', email='souryadipta.das@razorthink.com'), resource_spec=ResourceAllocated(cores=8, memory=36000, use_gpu=True, gpu=1, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-Engine-Load-Test').queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib2 = razor.api.libraries(name='pathos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
