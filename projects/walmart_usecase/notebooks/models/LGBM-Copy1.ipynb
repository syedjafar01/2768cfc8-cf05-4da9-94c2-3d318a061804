{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "HOST_HOME_DIR = str(pathlib.Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOST_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# razor.api.libraries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'cpu': 3, 'ram': 25000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor.flow as rf\n",
    "from razor.api import datasources\n",
    "from razor import project_space_path\n",
    "import razor\n",
    "from razor import Technology, LibraryMode\n",
    "# from razor.core.blocks import ContainerExecutor\n",
    "# from razor.core.blocks.transports import FileTransport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/project-space/M5Forecasting'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.normpath('/home/jovyan/project-space/M5Forecasting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(project_space_path('M5Forecasting/m5-simple-fe/grid_part_1 .pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=18000))\n",
    "class ConcatenateDF:\n",
    "    out_df: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "     \n",
    "    def init(self):\n",
    "        #PATHS for Features\n",
    "        self.ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "        self.BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1 .pkl')\n",
    "        self.PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "        self.CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "        \n",
    "    def run(self):\n",
    "        # Read and contact basic feature\n",
    "        df = pd.concat([pd.read_pickle(self.BASE),\n",
    "                        pd.read_pickle(self.PRICE).iloc[:,2:],\n",
    "                        pd.read_pickle(self.CALENDAR).iloc[:,2:]],\n",
    "                        axis=1)\n",
    "        self.out_df.put(df.iloc[:5, :5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_df = ConcatenateDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_df.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = razor.api.libraries(name='lightgbm').artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=18000))\n",
    "class Train:\n",
    "#     config: t.Any\n",
    "    concatenated_df: t.Any\n",
    "    train_CA_1: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_CA_1: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_CA_2: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_CA_2: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_CA_3: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_CA_3: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_CA_4: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_CA_4: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_TX_1: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_TX_1: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_TX_2: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_TX_2: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_TX_3: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_TX_3: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_WI_1: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_WI_1: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_WI_2: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_WI_2: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    train_WI_3: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    valid_WI_3: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "        \n",
    "        \n",
    "    __libs__ = [lib1]\n",
    "    \n",
    "    def init(self):\n",
    "        #PATHS for Features\n",
    "        self.ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "        self.BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1.pkl')\n",
    "        self.PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "        self.CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "        self.LAGS     = project_space_path('M5Forecasting/m5-lags-features/lags_df_28.pkl')\n",
    "        self.MEAN_ENC = project_space_path('M5Forecasting/m5-custom-features/mean_encoding_df.pkl')\n",
    "\n",
    "        #LIMITS and const\n",
    "        self.TARGET      = 'sales'            # Our target\n",
    "        self.START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "        self.END_TRAIN   = 1913               # End day of our train set\n",
    "        self.P_HORIZON   = 28                 # Prediction horizon\n",
    "        self.USE_AUX     = False               # Use or not pretrained models\n",
    "        self.N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "        # AUX(pretrained) Models paths\n",
    "        self.AUX_MODELS = '../input/m5-aux-models/'\n",
    "\n",
    "\n",
    "        #STORES ids\n",
    "        self.STORES_IDS = pd.read_csv(self.ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "        self.STORES_IDS = list(self.STORES_IDS.unique())\n",
    "\n",
    "\n",
    "        #SPLITS for lags creation\n",
    "        self.SHIFT_DAY  = 28\n",
    "        self.N_LAGS     = 15\n",
    "        self.LAGS_SPLIT = [col for col in range(self.SHIFT_DAY, self.SHIFT_DAY + self.N_LAGS)]\n",
    "\n",
    "            \n",
    "    def seed_everything(self, seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    ## Multiprocess Runs\n",
    "    def df_parallelize_run(self, func, t_split):\n",
    "        num_cores = np.min([self.N_CORES,len(t_split)])\n",
    "        pool = Pool(num_cores)\n",
    "        df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "\n",
    "    def get_data_by_store(self, df, store):\n",
    "\n",
    "        # Leave only relevant store\n",
    "        df = df[df['store_id']==store]\n",
    "\n",
    "        # With memory limits we have to read \n",
    "        # lags and mean encoding features\n",
    "        # separately and drop items that we don't need.\n",
    "        # As our Features Grids are aligned \n",
    "        # we can use index to keep only necessary rows\n",
    "        # Alignment is good for us as concat uses less memory than merge.\n",
    "        df2 = pd.read_pickle(self.MEAN_ENC)[mean_features]\n",
    "        df2 = df2[df2.index.isin(df.index)]\n",
    "\n",
    "        df = pd.concat([df, df2], axis=1)\n",
    "        del df2 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        df3 = pd.read_pickle(self.LAGS).iloc[:,3:]\n",
    "        df3 = df3[df3.index.isin(df.index)]\n",
    "\n",
    "\n",
    "        df = pd.concat([df, df3], axis=1)\n",
    "        del df3 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        # Create features list\n",
    "        features = [col for col in list(df) if col not in remove_features]\n",
    "        df = df[['id','d',self.TARGET]+features]\n",
    "\n",
    "        # Skipping first n rows\n",
    "        df = df[df['d']>=self.START_TRAIN].reset_index(drop=True)\n",
    "\n",
    "        return df, features\n",
    "\n",
    "    # Recombine Test set after training\n",
    "    def get_base_test(self):\n",
    "        base_test = pd.DataFrame()\n",
    "\n",
    "        for store_id in self.STORES_IDS:\n",
    "            temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "            temp_df['store_id'] = store_id\n",
    "            base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "\n",
    "        return base_test\n",
    "\n",
    "\n",
    "    ########################### Helper to make dynamic rolling lags\n",
    "    #################################################################################\n",
    "    def make_lag(self, LAG_DAY):\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'sales_lag_{str(LAG_DAY)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "        return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "    def make_lag_roll(self, LAG_DAY):\n",
    "        shift_day = LAG_DAY[0]\n",
    "        roll_wind = LAG_DAY[1]\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'rolling_mean_tmp_{str(shift_day)}_{str(roll_wind)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "        return lag_df[[col_name]]\n",
    "    \n",
    "    \n",
    "    def split_data(self, df, store_id):\n",
    "        logging.info('Train')\n",
    "        logging.info(store_id)\n",
    "\n",
    "        # Get grid for current store\n",
    "        grid_df, features_columns = self.get_data_by_store(df, store_id)\n",
    "\n",
    "        logging.info(\"Loaded grid Data\")\n",
    "\n",
    "        # Masks for \n",
    "        # Train (All data less than 1913)\n",
    "        # \"Validation\" (Last 28 days - not real validatio set)\n",
    "        # Test (All data greater than 1913 day, \n",
    "        #       with some gap for recursive features)\n",
    "        train_mask = grid_df['d']<=self.END_TRAIN\n",
    "        valid_mask = train_mask&(grid_df['d']>(self.END_TRAIN-self.P_HORIZON))\n",
    "        preds_mask = grid_df['d']>(self.END_TRAIN-100)\n",
    "\n",
    "        train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                           label=grid_df[train_mask][self.TARGET])\n",
    "\n",
    "#             train_data.save_binary(project_space_path(\"M5Forecasting/train_data.bin\"))\n",
    "#             train_data = lgb.Dataset(project_space_path(\"M5Forecasting/train_data.bin\"))\n",
    "\n",
    "        valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                           label=grid_df[valid_mask][self.TARGET])\n",
    "\n",
    "        # Saving part of the dataset for later predictions\n",
    "        # Removing features that we need to calculate recursively \n",
    "        grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "        keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "        grid_df = grid_df[keep_cols]\n",
    "        grid_df.to_pickle(project_space_path(f\"M5Forecasting/test_{store_id}.pkl\"))\n",
    "        del grid_df\n",
    "        gc.collect()\n",
    "        \n",
    "        return train_data, valid_data\n",
    "            \n",
    "    \n",
    "    def run(self):\n",
    "                         \n",
    "        import logging\n",
    "\n",
    "\n",
    "        import lightgbm as lgb\n",
    "        lgb_params = {\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'objective': 'tweedie',\n",
    "                            'tweedie_variance_power': 1.1,\n",
    "                            'metric': 'rmse',\n",
    "                            'subsample': 0.5,\n",
    "                            'subsample_freq': 1,\n",
    "                            'learning_rate': 0.03,\n",
    "                            'num_leaves': 2**11-1,\n",
    "                            'min_data_in_leaf': 2**12-1,\n",
    "                            'feature_fraction': 0.5,\n",
    "                            'max_bin': 100,\n",
    "                            'n_estimators': 1400,\n",
    "                            'boost_from_average': False,\n",
    "                            'verbose': -1,\n",
    "                        } \n",
    "\n",
    "\n",
    "                ########################### Vars\n",
    "        #################################################################################\n",
    "        VER = 1                          # Our model version\n",
    "        SEED = 42                      \n",
    "        self.seed_everything(SEED)      \n",
    "        lgb_params['seed'] = SEED        \n",
    "\n",
    "        #FEATURES to remove\n",
    "        ## These features lead to overfit\n",
    "        ## or values not present in test set\n",
    "        remove_features = ['id','state_id','store_id',\n",
    "                           'date','wm_yr_wk','d', self.TARGET]\n",
    "        mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                           'enc_dept_id_mean','enc_dept_id_std',\n",
    "                           'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "\n",
    "        ROLS_SPLIT = []\n",
    "        \n",
    "        for i in [1,7,14]:\n",
    "            for j in [7,14,30,60]:\n",
    "                ROLS_SPLIT.append([i,j])\n",
    "\n",
    "\n",
    "        if self.USE_AUX:\n",
    "            lgb_params['n_estimators'] = 2\n",
    "\n",
    "        \n",
    "\n",
    "        df = self.concatenated_df\n",
    "        train_data_CA_1, valid_data_CA_1 = self.split_data(df, 'CA_1')\n",
    "        train_data_CA_2, valid_data_CA_2 = self.split_data(df, 'CA_2')\n",
    "        train_data_CA_3, valid_data_CA_3 = self.split_data(df, 'CA_3')\n",
    "        train_data_CA_4, valid_data_CA_4 = self.split_data(df, 'CA_4')\n",
    "        train_data_TX_1, valid_data_TX_1 = self.split_data(df, 'TX_1')\n",
    "        train_data_TX_2, valid_data_TX_2 = self.split_data(df, 'TX_2')\n",
    "        train_data_TX_3, valid_data_TX_3 = self.split_data(df, 'TX_3')\n",
    "        train_data_WI_1, valid_data_WI_1 = self.split_data(df, 'WI_1')\n",
    "        train_data_WI_2, valid_data_WI_2 = self.split_data(df, 'WI_2')\n",
    "        train_data_WI_3, valid_data_WI_3 = self.split_data(df, 'WI_3')\n",
    "        \n",
    "        self.train_CA_1.put(train_data_CA_1)\n",
    "        self.valid_CA_1.put(valid_data_CA_1)\n",
    "        \n",
    "        self.train_CA_2.put(train_data_CA_2)\n",
    "        self.valid_CA_2.put(valid_data_CA_2)\n",
    "        \n",
    "        self.train_CA_3.put(train_data_CA_3)\n",
    "        self.valid_CA_3.put(valid_data_CA_3)\n",
    "        \n",
    "        self.train_CA_4.put(train_data_CA_4)\n",
    "        self.valid_CA_4.put(valid_data_CA_4)\n",
    "\n",
    "        self.train_TX_1.put(train_data_TX_1)\n",
    "        self.valid_TX_1.put(valid_data_TX_1)\n",
    "        \n",
    "        self.train_TX_2.put(train_data_TX_2)\n",
    "        self.valid_TX_2.put(valid_data_TX_2)       \n",
    "        \n",
    "        self.train_TX_3.put(train_data_TX_3)\n",
    "        self.valid_TX_3.put(valid_data_TX_3) \n",
    "\n",
    "        self.train_WI_1.put(train_data_WI_1)\n",
    "        self.valid_WI_1.put(valid_data_WI_1) \n",
    "\n",
    "        self.train_WI_2.put(train_data_WI_2)\n",
    "        self.valid_WI_2.put(valid_data_WI_2) \n",
    "        \n",
    "        self.train_WI_3.put(train_data_WI_3)\n",
    "        self.valid_WI_3.put(valid_data_WI_3)         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=18000))\n",
    "class LGBMtrainer:\n",
    "#     config: t.Any\n",
    "    train_data: t.Any\n",
    "    valid_data: t.Any\n",
    "    \n",
    "    __libs__ = [lib1]\n",
    "    \n",
    "    def init(self):\n",
    "        #PATHS for Features\n",
    "        self.ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "        self.BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1 .pkl')\n",
    "        self.PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "        self.CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "        self.LAGS     = project_space_path('M5Forecasting/m5-lags-features/lags_df_28.pkl')\n",
    "        self.MEAN_ENC = project_space_path('M5Forecasting/m5-custom-features/mean_encoding_df.pkl')\n",
    "\n",
    "        #LIMITS and const\n",
    "        self.TARGET      = 'sales'            # Our target\n",
    "        self.START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "        self.END_TRAIN   = 1913               # End day of our train set\n",
    "        self.P_HORIZON   = 28                 # Prediction horizon\n",
    "        self.USE_AUX     = False               # Use or not pretrained models\n",
    "        self.N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "        # AUX(pretrained) Models paths\n",
    "        self.AUX_MODELS = '../input/m5-aux-models/'\n",
    "\n",
    "\n",
    "        #STORES ids\n",
    "        self.STORES_IDS = pd.read_csv(self.ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "        self.STORES_IDS = list(self.STORES_IDS.unique())\n",
    "\n",
    "\n",
    "        #SPLITS for lags creation\n",
    "        self.SHIFT_DAY  = 28\n",
    "        self.N_LAGS     = 15\n",
    "        self.LAGS_SPLIT = [col for col in range(self.SHIFT_DAY, self.SHIFT_DAY + self.N_LAGS)]\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        import lightgbm as lgb\n",
    "\n",
    "        lgb_params = {\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'objective': 'tweedie',\n",
    "                            'tweedie_variance_power': 1.1,\n",
    "                            'metric': 'rmse',\n",
    "                            'subsample': 0.5,\n",
    "                            'subsample_freq': 1,\n",
    "                            'learning_rate': 0.03,\n",
    "                            'num_leaves': 2**11-1,\n",
    "                            'min_data_in_leaf': 2**12-1,\n",
    "                            'feature_fraction': 0.5,\n",
    "                            'max_bin': 100,\n",
    "                            'n_estimators': 1400,\n",
    "                            'boost_from_average': False,\n",
    "                            'verbose': -1,\n",
    "                        } \n",
    "\n",
    "\n",
    "                ########################### Vars\n",
    "        #################################################################################\n",
    "        VER = 1                          # Our model version\n",
    "        SEED = 42                      \n",
    "        self.seed_everything(SEED)      \n",
    "        lgb_params['seed'] = SEED \n",
    "\n",
    "\n",
    "        self.seed_everything(SEED)\n",
    "        estimator = lgb.train(lgb_params,\n",
    "                              self.train_data,\n",
    "                              valid_sets = [self.valid_data],\n",
    "                              verbose_eval = 100,\n",
    "                              )\n",
    "\n",
    "\n",
    "        model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "        pickle.dump(estimator, open(project_space_path(f\"M5Forecasting/{model_name}\", 'wb')))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Train(concatenated_df=conc_df.out_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_1 = LGBMtrainer(train_data=train.train_CA_1, valid_data=train.valid_CA_1)\n",
    "CA_2 = LGBMtrainer(train_data=train.train_CA_2, valid_data=train.valid_CA_2)\n",
    "CA_3 = LGBMtrainer(train_data=train.train_CA_3, valid_data=train.valid_CA_3)\n",
    "CA_4 = LGBMtrainer(train_data=train.train_CA_4, valid_data=train.valid_CA_4)\n",
    "TX_1 = LGBMtrainer(train_data=train.train_TX_1, valid_data=train.valid_TX_1)\n",
    "TX_2 = LGBMtrainer(train_data=train.train_TX_2, valid_data=train.valid_TX_2)\n",
    "TX_3 = LGBMtrainer(train_data=train.train_TX_3, valid_data=train.valid_TX_3)\n",
    "WI_1 = LGBMtrainer(train_data=train.train_WI_1, valid_data=train.valid_WI_1)\n",
    "WI_2 = LGBMtrainer(train_data=train.train_WI_2, valid_data=train.valid_WI_2)\n",
    "WI_3 = LGBMtrainer(train_data=train.train_WI_3, valid_data=train.valid_WI_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = rf.Pipeline(\"Train\", targets=[CA_1, CA_2, CA_3, CA_4, TX_1, TX_2, TX_3, WI_1, WI_2, WI_3])  #preprocess\n",
    "p = rf.Pipeline(\"Train\", targets=[conc_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.interactive+pipeline+view+json": {
       "blocks": [
        {
         "class_name": "ConcatenateDF",
         "id": "f228f5b8-fa43-4dc0-96f8-d971d7bd3e6f",
         "inputs": [],
         "outputs": [
          {
           "flow": "atomic",
           "help": null,
           "label": "out_df",
           "name": "out_df",
           "series": false,
           "type": "Any",
           "type_check": true
          }
         ],
         "overwritten": false,
         "var_names": [
          "ConcatenateDF"
         ]
        }
       ],
       "connections": [],
       "id": "d1467584-c265-42d1-acc6-03c1fc885f0c",
       "instances": [
        {
         "block_class": "f228f5b8-fa43-4dc0-96f8-d971d7bd3e6f",
         "id": "3ddac5de-e9ed-493c-913c-520ec6523da5",
         "name": "ConcatenateDF_1",
         "var_names": [
          "conc_df"
         ]
        }
       ],
       "name": "Train",
       "var_names": []
      },
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"232pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 231.69 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 227.6919,-40 227.6919,4 -4,4\"/>\n",
       "<!-- ConcatenateDF(&#39;ConcatenateDF_1&#39;) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>ConcatenateDF(&#39;ConcatenateDF_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"111.846\" cy=\"-18\" rx=\"111.6921\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"111.846\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#000000\">ConcatenateDF(&#39;ConcatenateDF_1&#39;)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<razor.flow.pipeline.Pipeline at 0x7f9d0c28f710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib1 = razor.api.libraries(name='lightgbm').artifact()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_pipeline = razor.api.engines('DS-Engine-Load-Test').execute(pipeline=p)\n",
    "deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.run+monitor+json": "/home/jovyan/logs/9379b1c4-8a3e-4fc8-bc3f-32e7bf1c9efa",
      "text/plain": [
       "<razor_tools.backend.ipython.mime.run_monitor.RunMonitor at 0x7f9d0c0fae90>"
      ]
     },
     "metadata": {
      "application/vnd.razorthink.run+monitor+json": {
       "store_in_notebook": false
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "PlatformPipelineRun(project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', pipeline_id='36c23788-fe39-11ea-968a-0242ac110005', pipeline_name='Train', pipeline_run_id='9379b1c4-8a3e-4fc8-bc3f-32e7bf1c9efa', pipeline_version=None, comment=None, created_on='2020-09-24T07:40:29.214+00:00', start_time=None, end_time=None, eta=0, run_at=1600933229214, run_duration=0, compute_time=0, wait_time=549, ran_by_user=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), status='IN_PROGRESS', block_status=[PlatformPipelineBlockRun(pipeline_run_id='9379b1c4-8a3e-4fc8-bc3f-32e7bf1c9efa', pipeline_name='Train', pipeline_status='IN_PROGRESS', block_id='c0c6743b-c463-4a49-8a82-6b8762da15f6', block_run_id='55b00575-a865-4090-8aac-0199dd76784a', block_name='ConcatenateDF_1', resource_spec=ResourceAllocated(cores=2, memory=18000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'), technology='PYTHON', status='READY_TO_GO', containers=[], cluster_id='c0c6743b-c463-4a49-8a82-6b8762da15f6', _log=None, _metric=None, wait_time=0, compute_time=0, start_time=None, end_time=None, queued_at='2020-09-24T07:40:29.000+00:00')], run_number=147, pipeline_variable_list=[], block_run_details=[BlockRunDetail(block_id='c0c6743b-c463-4a49-8a82-6b8762da15f6', block_run_id='55b00575-a865-4090-8aac-0199dd76784a', block_name='ConcatenateDF_1', technology='PYTHON', log_path=None, input_parameters='{}', output_parameters=None, status='READY_TO_GO', created_at='2020-09-24T07:40:29.331+00:00', queued_at='2020-09-24T07:40:29.000+00:00', start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[BlockRunOutputList(output_id='6d3fa4ed-ef5d-4015-a7d0-98634a73e68b', output_name='out_df', created_on='2020-09-24T07:40:29.367+00:00', output_status='YET_TO_START', block_transport='FILE')], resource_allocated=ResourceAllocated(cores=2, memory=18000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))], pipeline_json='{\\n  \"id\": \"36c23788-fe39-11ea-968a-0242ac110005\",\\n  \"projectId\": \"c0b26d85-a4c9-44f5-9d0e-f540dd2de644\",\\n  \"name\": \"Train\",\\n  \"description\": \"\",\\n  \"blocks\": [\\n    {\\n      \"name\": \"ConcatenateDF_1\",\\n      \"id\": \"c0c6743b-c463-4a49-8a82-6b8762da15f6\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"ConcatenateDF\",\\n      \"code\": \"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\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {},\\n      \"outputProperty\": {\\n        \"out_df\": {\\n          \"series\": false,\\n          \"adapter\": \"eJxrYJmqxgABPYJFiVX5RXppOfnlern5Kak5xVN6ePLy8wviE1MSC0pSi6ZMnqIHAF/+ELQ=\",\\n          \"transport\": \"FILE\"\\n        }\\n      },\\n      \"resourceRequirement\": {\\n        \"cores\": 2,\\n        \"memory\": 18000,\\n        \"useGpu\": false,\\n        \"gpu\": 0,\\n        \"useGpuIfAvailable\": false,\\n        \"clusterConfiguration\": {\\n          \"worker\": null,\\n          \"workerCore\": null,\\n          \"workerMemory\": null,\\n          \"numberOfInstances\": null,\\n          \"maxServerCount\": null\\n        },\\n        \"additionalEnv\": {},\\n        \"runEnv\": \"PYTHON\"\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"process_id\": null,\\n      \"eta\": 0\\n    }\\n  ],\\n  \"connections\": [],\\n  \"priority\": \"LOW\",\\n  \"infraResourceEstimation\": null,\\n  \"resourceRequirement\": {\\n    \"cores\": null,\\n    \"memory\": null,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"comments\": null,\\n  \"order\": null,\\n  \"uiData\": null,\\n  \"dom\": null,\\n  \"systemGenerated\": false,\\n  \"systemModel\": false,\\n  \"pipelineVariableList\": [],\\n  \"pipelineTemplateVersion\": 0.0,\\n  \"versionId\": null,\\n  \"engineId\": \"65ed2499-f8c9-4c4d-ad27-aa689bd1531e\",\\n  \"userId\": \"c4080201-ccc9-4657-a457-7e18c100ff28\",\\n  \"runInitiatedFrom\": \"JUPYTER\",\\n  \"processList\": null,\\n  \"processInfo\": null\\n}', dom='Yet to add', order=None, infra_resource='{\\n  \"zookeeper\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"kafka\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  }\\n}', resource_spec=ResourceAllocated(cores=None, memory=None, use_gpu=None, gpu=None, use_gpu_if_available=None, cluster_configuration=None, additional_env={}, run_env=None), engine_id='65ed2499-f8c9-4c4d-ad27-aa689bd1531e', run_initiated_from='JUPYTER')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "\t<table width='100%'>\n",
       "\t\t<tr'><th>Slave Host</th><th>Type</th><th colspan='3' style='text-align: center;'>Usage</th></tr>\n",
       "\t\t<tbody>\n",
       "\t\t\t<tr><td>172.16.104.139 </td><td> INFRASTRUCTURE </td><td> CORE: Used 8 of 16 (50.0%)</td><td>RAM: Used 8.0 of 38.0GB (21.052631578947366%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.114.99 </td><td> TECHNOLOGY </td><td> CORE: Used 27 of 32 (84.375%)</td><td>RAM: Used 54.109375 of 115.0GB (47.05163043478261%)</td></tr>\n",
       "\n",
       "\t\t</tbody>\n",
       "\t</table>\n",
       "</html>"
      ],
      "text/plain": [
       "PlatformEngineHealthList(slave_usage_array=[PlatformEngineHealth(server_ip='172.16.104.139', server_type='INFRASTRUCTURE', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=16, used=8, available=8, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=40802189312.0, used=8589934592.0, available=32212254720.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')]), PlatformEngineHealth(server_ip='172.16.114.99', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=32, used=27, available=5, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=123480309760.0, used=58099499008.0, available=65380810752.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-engine').health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <html>\n",
       "            <body>\n",
       "                <h4>Engine Queue</h4>\n",
       "                <h4>Number of queued blocks: 2</h4>\n",
       "                <table width='100%'>\n",
       "                <tr>\n",
       "                    <th style='align:left; text-align:left;'>Block</th>\n",
       "                    <th style='align:left; text-align:left;'>Pipeline</th>\n",
       "                    <th style='align:left; text-align:left;'>Wait Time(hours:minutes:seconds)</th>\n",
       "                </tr>\n",
       "        \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>Filter_1</td>\n",
       "                    <td style='align:left; text-align:left;'>Pipeline_9</td>\n",
       "                    <td style='align:left; text-align:left;'>0:10:38</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>ConcatenateDF_1</td>\n",
       "                    <td style='align:left; text-align:left;'>Train</td>\n",
       "                    <td style='align:left; text-align:left;'>0:02:17</td>\n",
       "                </tr>\n",
       "            \n",
       "                </table>\n",
       "            </body>\n",
       "        </html>\n",
       "        "
      ],
      "text/plain": [
       "PlatformQueueStatusList(queue_list=[PlatformQueueStatus(block_run_id='5a69d39c-ed09-4d34-87e7-0bfbdbfa0337', block_id='546ebcd6-bae1-415f-a7d8-3dd9ada03628', block_name='Filter_1', pipeline_run_id='c8b511e1-81ac-4d01-b77e-862c7df1aab4', pipeline_id='d30657be-fe34-11ea-b4c5-0242ac110009', pipeline_name='Pipeline_9', project_id='71e127b9-c19f-41e0-bb54-c9d98d160fe1', wait_time=638, published_by=RanByUser(user_name='Aneesh K', email='aneesh.k@razorthink.com'), resource_spec=ResourceAllocated(cores=1, memory=1024, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': 1, 'workerCore': 10, 'workerMemory': 10240, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={'SPARK_EXECUTOR_INSTANCES': '1', 'SPARK_EXECUTOR_CORES': '10', 'SPARK_EXECUTOR_MEMORY': '10g'}, run_env='PY_SPARK')), PlatformQueueStatus(block_run_id='55b00575-a865-4090-8aac-0199dd76784a', block_id='c0c6743b-c463-4a49-8a82-6b8762da15f6', block_name='ConcatenateDF_1', pipeline_run_id='9379b1c4-8a3e-4fc8-bc3f-32e7bf1c9efa', pipeline_id='36c23788-fe39-11ea-968a-0242ac110005', pipeline_name='Train', project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', wait_time=137, published_by=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), resource_spec=ResourceAllocated(cores=2, memory=18000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-engine').queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/root/project-space/M5Forecasting/m5-simple-fe/grid_part_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/project-space'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_space_path('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "                    <h5>Pipeline: Train <span style='float:right; color:red'>Stopped by system<span></h5>\n",
       "                    <h5>Description: </h5>\n",
       "                    <h5>Comments: </h5>\n",
       "\n",
       "                    <table width='100%'>\n",
       "                        <tr>\n",
       "                            <th style='text-align:left;'>Run number</th>\n",
       "                            <th style='text-align:left;'>Version</th>\n",
       "                            <th style='text-align:left;'>Run at</th>\n",
       "                            <th style='text-align:left;'>Wait time</th>\n",
       "                            <th style='text-align:left;'>Compute time</th>\n",
       "                            <th style='text-align:left;'>Run by</th>\n",
       "                            <th style='text-align:left;'>Source</th>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style='text-align:left;'>137</td>\n",
       "                            <td style='text-align:left;'>None</td>\n",
       "                            <td style='text-align:left;'>Sep 21, 2020 09:53AM</td>\n",
       "                            <td style='text-align:left;'>6.52 s</td>\n",
       "                            <td style='text-align:left;'>48.57 s</td>\n",
       "                            <td style='text-align:left;'>Ayan Basak</td>\n",
       "                            <td style='text-align:left;'>Jupyter</td>\n",
       "                        </tr>\n",
       "                    </table><h5>Pipeline-level Resource Spec: </h5>\n",
       "                    <table width='100%'>\n",
       "                        <tr>\n",
       "                            <th style='text-align:left;'>CPU Cores</th>\n",
       "                            <th style='text-align:left;'>Memory</th>\n",
       "                            <th style='text-align:left;'>GPU Required</th>\n",
       "                            <th style='text-align:left;'>GPUs</th>\n",
       "                            <th style='text-align:left;'>Use GPU if available</th>\n",
       "                        </tr>\n",
       "                        <tr>\n",
       "                            <td style='text-align:left;'>None</td>\n",
       "                            <td style='text-align:left;'>NoneMB</td>\n",
       "                            <td style='text-align:left;'>None</td>\n",
       "                            <td style='text-align:left;'>None</td>\n",
       "                            <td style='text-align:left;'>None</td>\n",
       "                        </tr>\n",
       "                    </table><h5>Blocks: </h5>\n",
       "\n",
       "                  <table width='100%'>\n",
       "                      <tr>\n",
       "                          <th style='text-align:left;'>Block</th>\n",
       "                          <th style='text-align:left;'>Status</th>\n",
       "                          <th style='text-align:left;'>Technology</th>\n",
       "                          <th style='text-align:left;'>Wait time</th>\n",
       "                          <th style='text-align:left;'>Compute time</th>\n",
       "                          <th style='text-align:left;'>Resource spec</th>\n",
       "                      </tr>\n",
       "                <tr>\n",
       "                            <td style='text-align:left;'>ConcatenateDF_1</td>\n",
       "                            <td style='text-align:left; color: red'>Killed</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>6.0 s</td>\n",
       "                            <td style='text-align:left;'>48.0 s</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>Train_1</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_1</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_3</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_5</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_8</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_6</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_9</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_4</td>\n",
       "                            <td style='text-align:left; color: red'>Stopped by system</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_2</td>\n",
       "                            <td style='text-align:left; color: rgba(87, 101, 255, 1)'>Queued</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_10</td>\n",
       "                            <td style='text-align:left; color: rgba(87, 101, 255, 1)'>Queued</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    <tr>\n",
       "                            <td style='text-align:left;'>LGBMtrainer_7</td>\n",
       "                            <td style='text-align:left; color: rgba(87, 101, 255, 1)'>Queued</td>\n",
       "                            <td style='text-align:left;'>Python</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'>0 ms</td>\n",
       "                            <td style='text-align:left;'><pre>{\n",
       "    \"cores\": 2,\n",
       "    \"memory\": 18000,\n",
       "    \"use_gpu\": false,\n",
       "    \"gpu\": 0,\n",
       "    \"use_gpu_if_available\": false,\n",
       "    \"cluster_configuration\": {\n",
       "        \"worker\": null,\n",
       "        \"workerCore\": null,\n",
       "        \"workerMemory\": null,\n",
       "        \"numberOfInstances\": null,\n",
       "        \"maxServerCount\": null\n",
       "    },\n",
       "    \"additional_env\": {},\n",
       "    \"run_env\": \"PYTHON\"\n",
       "}</pre></td>\n",
       "                        </tr>\n",
       "                    </table>\n",
       "                </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deployed_pipeline.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "\t<table width='100%'>\n",
       "\t\t<tr'><th>Slave Host</th><th>Type</th><th colspan='3' style='text-align: center;'>Usage</th></tr>\n",
       "\t\t<tbody>\n",
       "\t\t\t<tr><td>172.16.115.94 </td><td> INFRASTRUCTURE </td><td> CORE: Used 10 of 16 (62.5%)</td><td>RAM: Used 10.0 of 38.0GB (26.31578947368421%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.114.99 </td><td> TECHNOLOGY </td><td> CORE: Used 7 of 32 (21.875%)</td><td>RAM: Used 28.53125 of 115.0GB (24.809782608695652%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.114.95 </td><td> TECHNOLOGY </td><td> CORE: Used 0 of 12 (0.0%)</td><td>RAM: Used 0.0 of 52.0GB (0.0%)</td><td>GPU: Used 0 of 1 (0.0%)</td></tr>\n",
       "\n",
       "\t\t</tbody>\n",
       "\t</table>\n",
       "</html>"
      ],
      "text/plain": [
       "PlatformEngineHealthList(slave_usage_array=[PlatformEngineHealth(server_ip='172.16.115.94', server_type='INFRASTRUCTURE', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=16, used=10, available=6, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=40802189312.0, used=10737418240.0, available=30064771072.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')]), PlatformEngineHealth(server_ip='172.16.114.99', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=32, used=7, available=25, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=123480309760.0, used=30635196416.0, available=92845113344.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')]), PlatformEngineHealth(server_ip='172.16.114.95', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=12, used=0, available=12, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=55834574848.0, used=0.0, available=55834574848.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=1, used=0, available=1, value='GPU')])])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-engine').health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine Test set after training\n",
    "def get_base_test():\n",
    "    import time\n",
    "    \n",
    "    \n",
    "    def df_parallelize_run(func, t_split):\n",
    "        num_cores = np.min([N_CORES,len(t_split)])\n",
    "        pool = Pool(num_cores)\n",
    "        df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "    \n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "\n",
    "    return base_test\n",
    "    \n",
    "    \n",
    "    VER = 1                          # Our model version\n",
    "    SEED = 42                        # We want all things\n",
    "    self.seed_everything(SEED)            # to be as deterministic \n",
    "    lgb_params['seed'] = SEED        # as possible\n",
    "    N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "    #LIMITS and const\n",
    "    TARGET      = 'sales'            # Our target\n",
    "    START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "    END_TRAIN   = 1913               # End day of our train set\n",
    "    P_HORIZON   = 28                 # Prediction horizon\n",
    "    USE_AUX     = True               # Use or not pretrained models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/models'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
