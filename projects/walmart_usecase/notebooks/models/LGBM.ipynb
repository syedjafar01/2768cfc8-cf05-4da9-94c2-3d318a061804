{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "            <h4>Library</h4>\n",
       "            <table width='100%'>\n",
       "                <tr>\n",
       "                    <th width='20%' style='align:left; text-align:center;'>Name</th>\n",
       "                    <th style='align:left; text-align:left;'>Technology</th>\n",
       "                    <th style='align:left; text-align:left;'>Install Status</th>\n",
       "                    <th style='align:left; text-align:left;'>Created by</th>\n",
       "                    <th style='align:left; text-align:left;'>Created on</th>\n",
       "                    <th style='align:left; text-align:left;'>Modified by</th>\n",
       "                    <th style='align:left; text-align:left;'>Modified on</th>\n",
       "                </tr><tr>\n",
       "                        <td width='20%' style='align:center; text-align:center;'>fastparquet</td>\n",
       "                        <td style='align:left; text-align:left;'>PYTHON</td>\n",
       "                        <td style='align:left; text-align:left;'>INSTALLED</td>\n",
       "                        <td style='align:left; text-align:left;'>Ayan Basak</td>\n",
       "                        <td style='align:left; text-align:left;'>Sep 25, 2020</td>\n",
       "                        <td style='align:left; text-align:left;'>Ayan Basak</td>\n",
       "                        <td style='align:left; text-align:left;'>Sep 25, 2020</td>\n",
       "                    </tr></table></html>"
      ],
      "text/plain": [
       "PlatformLibrary(id_='54865fdd-700e-494b-a8f8-0b6258aed7cf', artifact_version='01a8b174-7b78-4a53-bf28-5938922e4cd8', name='fastparquet', technology='PYTHON', installation_status='INSTALLED', created_by='Ayan Basak', created_on='2020-09-25T12:27:54.000+00:00', modified_by='Ayan Basak', modified_on='2020-09-25T12:27:54.000+00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.libraries('fastparquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'cpu': 2, 'ram': 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razor.flow as rf\n",
    "from razor.api import datasources\n",
    "from razor import project_space_path\n",
    "import razor\n",
    "from razor import Technology, LibraryMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################################################\n",
    "# ## Seeder\n",
    "# # :seed to make all processes deterministic     # type: int\n",
    "# def seed_everything(seed=0):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "    \n",
    "# ## Multiprocess Runs\n",
    "# def df_parallelize_run(func, t_split):\n",
    "#     num_cores = np.min([N_CORES,len(t_split)])\n",
    "#     pool = Pool(num_cores)\n",
    "#     df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Helper to load data by store ID\n",
    "# #################################################################################\n",
    "# # Read data\n",
    "# def get_data_by_store(store):\n",
    "    \n",
    "#     # Read and contact basic feature\n",
    "#     df = pd.concat([pd.read_pickle(BASE),\n",
    "#                     pd.read_pickle(PRICE).iloc[:,2:],\n",
    "#                     pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "#                     axis=1)\n",
    "    \n",
    "#     # Leave only relevant store\n",
    "#     df = df[df['store_id']==store]\n",
    "\n",
    "#     # With memory limits we have to read \n",
    "#     # lags and mean encoding features\n",
    "#     # separately and drop items that we don't need.\n",
    "#     # As our Features Grids are aligned \n",
    "#     # we can use index to keep only necessary rows\n",
    "#     # Alignment is good for us as concat uses less memory than merge.\n",
    "#     df2 = pd.read_pickle(MEAN_ENC)[mean_features]\n",
    "#     df2 = df2[df2.index.isin(df.index)]\n",
    "    \n",
    "#     df3 = pd.read_pickle(LAGS).iloc[:,3:]\n",
    "#     df3 = df3[df3.index.isin(df.index)]\n",
    "    \n",
    "#     df = pd.concat([df, df2], axis=1)\n",
    "#     del df2 # to not reach memory limit \n",
    "    \n",
    "#     df = pd.concat([df, df3], axis=1)\n",
    "#     del df3 # to not reach memory limit \n",
    "    \n",
    "#     # Create features list\n",
    "#     features = [col for col in list(df) if col not in remove_features]\n",
    "#     df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "#     # Skipping first n rows\n",
    "#     df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "#     return df, features\n",
    "\n",
    "# # Recombine Test set after training\n",
    "# def get_base_test():\n",
    "#     base_test = pd.DataFrame()\n",
    "\n",
    "#     for store_id in STORES_IDS:\n",
    "#         temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "#         temp_df['store_id'] = store_id\n",
    "#         base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "#     return base_test\n",
    "\n",
    "\n",
    "# ########################### Helper to make dynamic rolling lags\n",
    "# #################################################################################\n",
    "# def make_lag(LAG_DAY):\n",
    "#     lag_df = base_test[['id','d',TARGET]]\n",
    "#     col_name = f'sales_lag_{str(LAG_DAY)}'\n",
    "#     lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "#     return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "# def make_lag_roll(LAG_DAY):\n",
    "#     shift_day = LAG_DAY[0]\n",
    "#     roll_wind = LAG_DAY[1]\n",
    "#     lag_df = base_test[['id','d',TARGET]]\n",
    "#     col_name = f'rolling_mean_tmp_{str(shift_day)}_{str(roll_wind)}'\n",
    "#     lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "#     return lag_df[[col_name]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Model params\n",
    "# #################################################################################\n",
    "# import lightgbm as lgb\n",
    "# lgb_params = {\n",
    "#                     'boosting_type': 'gbdt',\n",
    "#                     'objective': 'tweedie',\n",
    "#                     'tweedie_variance_power': 1.1,\n",
    "#                     'metric': 'rmse',\n",
    "#                     'subsample': 0.5,\n",
    "#                     'subsample_freq': 1,\n",
    "#                     'learning_rate': 0.03,\n",
    "#                     'num_leaves': 2**11-1,\n",
    "#                     'min_data_in_leaf': 2**12-1,\n",
    "#                     'feature_fraction': 0.5,\n",
    "#                     'max_bin': 100,\n",
    "#                     'n_estimators': 1400,\n",
    "#                     'boost_from_average': False,\n",
    "#                     'verbose': -1,\n",
    "#                 } \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Vars\n",
    "# #################################################################################\n",
    "# VER = 1                          # Our model version\n",
    "# SEED = 42                        # We want all things\n",
    "# seed_everything(SEED)            # to be as deterministic \n",
    "# lgb_params['seed'] = SEED        # as possible\n",
    "# N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "# #LIMITS and const\n",
    "# TARGET      = 'sales'            # Our target\n",
    "# START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "# END_TRAIN   = 1913               # End day of our train set\n",
    "# P_HORIZON   = 28                 # Prediction horizon\n",
    "# USE_AUX     = True               # Use or not pretrained models\n",
    "\n",
    "# #FEATURES to remove\n",
    "# ## These features lead to overfit\n",
    "# ## or values not present in test set\n",
    "# remove_features = ['id','state_id','store_id',\n",
    "#                    'date','wm_yr_wk','d', TARGET]\n",
    "# mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "#                    'enc_dept_id_mean','enc_dept_id_std',\n",
    "#                    'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "\n",
    "# base_df = pd.read_csv(project_space_path(\"M5Forecasting/sales_train_validation.csv\"))\n",
    "# price_df = pd.read_csv(project_space_path(\"M5Forecasting/sell_prices.csv\"))\n",
    "# calendar_df = pd.read_csv(project_space_path(\"M5Forecasting/calendar.csv\"))\n",
    "\n",
    "# base_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_1.pkl'))\n",
    "# price_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl'))\n",
    "# calendar_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl'))\n",
    "\n",
    "# #PATHS for Features\n",
    "# ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "# BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1.pkl')\n",
    "# PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "# CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "# LAGS     = project_space_path('M5Forecasting/m5-lags-features/lags_df_28.pkl')\n",
    "# MEAN_ENC = project_space_path('M5Forecasting/m5-custom-features/mean_encoding_df.pkl')\n",
    "\n",
    "\n",
    "# # AUX(pretrained) Models paths\n",
    "# AUX_MODELS = '../input/m5-aux-models/'\n",
    "\n",
    "\n",
    "# #STORES ids\n",
    "# STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "# STORES_IDS = list(STORES_IDS.unique())\n",
    "\n",
    "\n",
    "# #SPLITS for lags creation\n",
    "# SHIFT_DAY  = 28\n",
    "# N_LAGS     = 15\n",
    "# LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n",
    "# ROLS_SPLIT = []\n",
    "# for i in [1,7,14]:\n",
    "#     for j in [7,14,30,60]:\n",
    "#         ROLS_SPLIT.append([i,j])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Aux Models\n",
    "# # If you don't want to wait hours and hours\n",
    "# # to have result you can train each store \n",
    "# # in separate kernel and then just join result.\n",
    "\n",
    "# # If we want to use pretrained models we can \n",
    "# ## skip training \n",
    "# ## (in our case do dummy training\n",
    "# ##  to show that we are good with memory\n",
    "# ##  and you can safely use this (all kernel) code)\n",
    "# if USE_AUX:\n",
    "#     lgb_params['n_estimators'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### Train Models\n",
    "# #################################################################################\n",
    "# for store_id in STORES_IDS:\n",
    "#     print('Train', store_id)\n",
    "    \n",
    "#     # Get grid for current store\n",
    "#     grid_df, features_columns = get_data_by_store(store_id)\n",
    "    \n",
    "#     # Masks for \n",
    "#     # Train (All data less than 1913)\n",
    "#     # \"Validation\" (Last 28 days - not real validatio set)\n",
    "#     # Test (All data greater than 1913 day, \n",
    "#     #       with some gap for recursive features)\n",
    "#     train_mask = grid_df['d']<=END_TRAIN\n",
    "#     valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "#     preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "#     train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "#                        label=grid_df[train_mask][TARGET])\n",
    "#     train_data.save_binary(project_space_path(\"M5Forecasting/train_data.bin\"))\n",
    "#     train_data = lgb.Dataset(project_space_path(\"M5Forecasting/train_data.bin\"))\n",
    "    \n",
    "#     valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "#                        label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "#     # Saving part of the dataset for later predictions\n",
    "#     # Removing features that we need to calculate recursively \n",
    "#     grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "#     keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "#     grid_df = grid_df[keep_cols]\n",
    "#     grid_df.to_pickle(project_space_path(f\"M5Forecasting/test_{store_id}.pkl\"))\n",
    "#     del grid_df\n",
    "    \n",
    "#     # Launch seeder again to make lgb training 100% deterministic\n",
    "#     # with each \"code line\" np.random \"evolves\" \n",
    "#     # so we need (may want) to \"reset\" it\n",
    "#     seed_everything(SEED)\n",
    "#     estimator = lgb.train(lgb_params,\n",
    "#                           train_data,\n",
    "#                           valid_sets = [valid_data],\n",
    "#                           verbose_eval = 100,\n",
    "#                           )\n",
    "    \n",
    "#     # Save model - it's not real '.bin' but a pickle file\n",
    "#     # estimator = lgb.Booster(model_file='model.txt')\n",
    "#     # can only predict with the best iteration (or the saving iteration)\n",
    "#     # pickle.dump gives us more flexibility\n",
    "#     # like estimator.predict(TEST, num_iteration=100)\n",
    "#     # num_iteration - number of iteration want to predict with, \n",
    "#     # NULL or <= 0 means use best iteration\n",
    "#     model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "#     pickle.dump(estimator, open(project_space_path(f\"M5Forecasting/{model_name}\", 'wb'))\n",
    "\n",
    "#     # Remove temporary files and objects \n",
    "#     # to free some hdd space and ram memory\n",
    "# #     !rm train_data.bin\n",
    "                \n",
    "#     del train_data, valid_data, estimator\n",
    "#     gc.collect()\n",
    "    \n",
    "#     # \"Keep\" models features for predictions\n",
    "#     MODEL_FEATURES = features_columns\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = razor.api.libraries(name='lightgbm').artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=config['cpu'], memory=config['ram']))\n",
    "class Train:\n",
    "#     config: t.Any\n",
    "    \n",
    "    __libs__ = [lib1]\n",
    "    \n",
    "    def init(self):\n",
    "        #PATHS for Features\n",
    "        self.ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "        self.BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1 .pkl')\n",
    "        self.PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "        self.CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "        self.LAGS     = project_space_path('M5Forecasting/lags_df_28.pkl')\n",
    "        self.MEAN_ENC = project_space_path('M5Forecasting/mean_encoding_df.pkl')\n",
    "\n",
    "        #LIMITS and const\n",
    "        self.TARGET      = 'sales'            # Our target\n",
    "        self.START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "        self.END_TRAIN   = 1913               # End day of our train set\n",
    "        self.P_HORIZON   = 28                 # Prediction horizon\n",
    "        self.USE_AUX     = False               # Use or not pretrained models\n",
    "        self.N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "        # AUX(pretrained) Models paths\n",
    "        self.AUX_MODELS = '../input/m5-aux-models/'\n",
    "\n",
    "\n",
    "        #STORES ids\n",
    "        self.STORES_IDS = pd.read_csv(self.ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "        self.STORES_IDS = list(self.STORES_IDS.unique())\n",
    "\n",
    "\n",
    "        #SPLITS for lags creation\n",
    "        self.SHIFT_DAY  = 28\n",
    "        self.N_LAGS     = 15\n",
    "        self.LAGS_SPLIT = [col for col in range(self.SHIFT_DAY, self.SHIFT_DAY + self.N_LAGS)]\n",
    "        \n",
    "        self.remove_features = ['id','state_id','store_id',\n",
    "                           'date','wm_yr_wk','d', self.TARGET]\n",
    "        self.mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                           'enc_dept_id_mean','enc_dept_id_std',\n",
    "                           'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "            \n",
    "    def seed_everything(self, seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    ## Multiprocess Runs\n",
    "    def df_parallelize_run(self, func, t_split):\n",
    "        num_cores = np.min([self.N_CORES,len(t_split)])\n",
    "        pool = Pool(num_cores)\n",
    "        df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "\n",
    "    def get_data_by_store(self, store):\n",
    "\n",
    "        # Read and contact basic feature\n",
    "        df1 = pd.read_pickle(self.BASE)\n",
    "#         df1 = df1[df1['store_id']==store]\n",
    "        df2 = pd.read_pickle(self.PRICE).iloc[:,2:]\n",
    "#         df2 = df2[df2['store_id']==store]\n",
    "        df3 = pd.read_pickle(self.CALENDAR).iloc[:,2:]\n",
    "        df = pd.concat([df1, df2, df3],\n",
    "                        axis=1)\n",
    "\n",
    "        # Leave only relevant store\n",
    "        df = df[df['store_id']==store]\n",
    "\n",
    "        # With memory limits we have to read \n",
    "        # lags and mean encoding features\n",
    "        # separately and drop items that we don't need.\n",
    "        # As our Features Grids are aligned \n",
    "        # we can use index to keep only necessary rows\n",
    "        # Alignment is good for us as concat uses less memory than merge.\n",
    "        df2 = pd.read_pickle(self.MEAN_ENC)[self.mean_features]\n",
    "        df2 = df2[df2.index.isin(df.index)]\n",
    "\n",
    "        df = pd.concat([df, df2], axis=1)\n",
    "        del df2 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        df3 = pd.read_pickle(self.LAGS).iloc[:,3:]\n",
    "        df3 = df3[df3.index.isin(df.index)]\n",
    "\n",
    "\n",
    "        df = pd.concat([df, df3], axis=1)\n",
    "        del df3 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        # Create features list\n",
    "        features = [col for col in list(df) if col not in self.remove_features]\n",
    "        df = df[['id','d',self.TARGET]+features]\n",
    "\n",
    "        # Skipping first n rows\n",
    "        df = df[df['d']>=self.START_TRAIN].reset_index(drop=True)\n",
    "\n",
    "        return df, features\n",
    "\n",
    "    # Recombine Test set after training\n",
    "    def get_base_test(self):\n",
    "        base_test = pd.DataFrame()\n",
    "\n",
    "        for store_id in self.STORES_IDS:\n",
    "            temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "            temp_df['store_id'] = store_id\n",
    "            base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "\n",
    "        return base_test\n",
    "\n",
    "\n",
    "    ########################### Helper to make dynamic rolling lags\n",
    "    #################################################################################\n",
    "    def make_lag(self, LAG_DAY):\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'sales_lag_{str(LAG_DAY)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "        return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "    def make_lag_roll(self, LAG_DAY):\n",
    "        shift_day = LAG_DAY[0]\n",
    "        roll_wind = LAG_DAY[1]\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'rolling_mean_tmp_{str(shift_day)}_{str(roll_wind)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "        return lag_df[[col_name]]\n",
    "    \n",
    "    def run(self):\n",
    "                         \n",
    "        import logging\n",
    "\n",
    "\n",
    "        import lightgbm as lgb\n",
    "        lgb_params = {\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'objective': 'tweedie',\n",
    "                            'tweedie_variance_power': 1.1,\n",
    "                            'metric': 'rmse',\n",
    "                            'subsample': 0.5,\n",
    "                            'subsample_freq': 1,\n",
    "                            'learning_rate': 0.03,\n",
    "                            'num_leaves': 2**11-1,\n",
    "                            'min_data_in_leaf': 2**12-1,\n",
    "                            'feature_fraction': 0.5,\n",
    "                            'max_bin': 100,\n",
    "                            'n_estimators': 1400,\n",
    "                            'boost_from_average': False,\n",
    "                            'verbose': -1,\n",
    "                        } \n",
    "\n",
    "\n",
    "                ########################### Vars\n",
    "        #################################################################################\n",
    "        VER = 1                          # Our model version\n",
    "        SEED = 42                      \n",
    "        self.seed_everything(SEED)      \n",
    "        lgb_params['seed'] = SEED        \n",
    "\n",
    "        #FEATURES to remove\n",
    "        ## These features lead to overfit\n",
    "        ## or values not present in test set\n",
    "\n",
    "\n",
    "\n",
    "#         base_df = pd.read_csv(project_space_path(\"M5Forecasting/sales_train_validation.csv\"))\n",
    "#         price_df = pd.read_csv(project_space_path(\"M5Forecasting/sell_prices.csv\"))\n",
    "#         calendar_df = pd.read_csv(project_space_path(\"M5Forecasting/calendar.csv\"))\n",
    "\n",
    "#         base_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_1.pkl'))\n",
    "#         price_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl'))\n",
    "#         calendar_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl'))\n",
    "\n",
    "        ROLS_SPLIT = []\n",
    "        \n",
    "        for i in [1,7,14]:\n",
    "            for j in [7,14,30,60]:\n",
    "                ROLS_SPLIT.append([i,j])\n",
    "\n",
    "\n",
    "        if self.USE_AUX:\n",
    "            lgb_params['n_estimators'] = 2\n",
    "\n",
    "        \n",
    "\n",
    "                ########################### Train Models\n",
    "        #################################################################################\n",
    "        for store_id in self.STORES_IDS:\n",
    "            logging.info('Train')\n",
    "            logging.info(store_id)\n",
    "\n",
    "            # Get grid for current store\n",
    "            grid_df, features_columns = self.get_data_by_store(store_id)\n",
    "            \n",
    "            logging.info(\"Loaded grid Data\")\n",
    "\n",
    "            # Masks for \n",
    "            # Train (All data less than 1913)\n",
    "            # \"Validation\" (Last 28 days - not real validatio set)\n",
    "            # Test (All data greater than 1913 day, \n",
    "            #       with some gap for recursive features)\n",
    "            train_mask = grid_df['d']<=self.END_TRAIN\n",
    "            valid_mask = train_mask&(grid_df['d']>(self.END_TRAIN-self.P_HORIZON))\n",
    "            preds_mask = grid_df['d']>(self.END_TRAIN-100)\n",
    "\n",
    "            train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                               label=grid_df[train_mask][self.TARGET])\n",
    "            \n",
    "#             train_data.save_binary(project_space_path(\"M5Forecasting/train_data.bin\"))\n",
    "#             train_data = lgb.Dataset(project_space_path(\"M5Forecasting/train_data.bin\"))\n",
    "\n",
    "            valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                               label=grid_df[valid_mask][self.TARGET])\n",
    "\n",
    "            # Saving part of the dataset for later predictions\n",
    "            # Removing features that we need to calculate recursively \n",
    "            grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "            keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "            grid_df = grid_df[keep_cols]\n",
    "            grid_df.to_pickle(project_space_path(f\"M5Forecasting/test_{store_id}.pkl\"))\n",
    "            del grid_df\n",
    "            gc.collect()\n",
    "\n",
    "            # Launch seeder again to make lgb training 100% deterministic\n",
    "            # with each \"code line\" np.random \"evolves\" \n",
    "            # so we need (may want) to \"reset\" it\n",
    "            self.seed_everything(SEED)\n",
    "            estimator = lgb.train(lgb_params,\n",
    "                                  train_data,\n",
    "                                  valid_sets = [valid_data],\n",
    "                                  verbose_eval = 100,\n",
    "                                  )\n",
    "\n",
    "\n",
    "            model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "            pickle.dump(estimator, open(project_space_path(f\"M5Forecasting/{model_name}\"), 'wb'))\n",
    "\n",
    "            # Remove temporary files and objects \n",
    "            # to free some hdd space and ram memory\n",
    "\n",
    "#             os.remove()\n",
    "            del train_data, valid_data, estimator\n",
    "            gc.collect()\n",
    "\n",
    "            # \"Keep\" models features for predictions\n",
    "            MODEL_FEATURES = features_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rf.Pipeline(\"Train\", targets=[train])  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.interactive+pipeline+view+json": {
       "blocks": [
        {
         "class_name": "Train",
         "id": "3be840d1-6dd3-40b8-8d92-0bd6e42295ff",
         "inputs": [],
         "outputs": [],
         "overwritten": false,
         "var_names": [
          "Train"
         ]
        }
       ],
       "connections": [],
       "id": "12af47c6-f84a-4bfb-9eb4-f873967a5899",
       "instances": [
        {
         "block_class": "3be840d1-6dd3-40b8-8d92-0bd6e42295ff",
         "id": "1c85be55-b023-4df1-85a0-c9d47faf4041",
         "name": "Train_1",
         "var_names": [
          "train"
         ]
        }
       ],
       "name": "Train",
       "var_names": []
      },
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"112pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 111.60 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 107.6047,-40 107.6047,4 -4,4\"/>\n",
       "<!-- Train(&#39;Train_1&#39;) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Train(&#39;Train_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"51.8023\" cy=\"-18\" rx=\"51.6054\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.8023\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#000000\">Train(&#39;Train_1&#39;)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<razor.flow.pipeline.Pipeline at 0x7f3188157110>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib1 = razor.api.libraries(name='lightgbm').artifact()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.run+monitor+json": "/home/jovyan/logs/b4da9914-e62d-4452-a24d-400e273c1d8a",
      "text/plain": [
       "<razor_tools.backend.ipython.mime.run_monitor.RunMonitor at 0x7f3182899bd0>"
      ]
     },
     "metadata": {
      "application/vnd.razorthink.run+monitor+json": {
       "store_in_notebook": false
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "PlatformPipelineRun(project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', pipeline_id='cd3d20ca-fe8d-11ea-ac5e-0242ac110005', pipeline_name='Train', pipeline_run_id='b4da9914-e62d-4452-a24d-400e273c1d8a', pipeline_version=None, comment=None, created_on='2020-09-24T17:45:57.945+00:00', start_time=None, end_time=None, eta=0, run_at=1600969557945, run_duration=0, compute_time=0, wait_time=219, ran_by_user=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), status='IN_PROGRESS', block_status=[PlatformPipelineBlockRun(pipeline_run_id='b4da9914-e62d-4452-a24d-400e273c1d8a', pipeline_name='Train', pipeline_status='IN_PROGRESS', block_id='1dab4f69-40fa-4285-aa28-1061ec96940b', block_run_id='c0fdf7f2-4762-4316-b333-2a7e29e3d11c', block_name='Train_1', resource_spec=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'), technology='PYTHON', status='READY_TO_GO', containers=[], cluster_id='1dab4f69-40fa-4285-aa28-1061ec96940b', _log=None, _metric=None, wait_time=0, compute_time=0, start_time=None, end_time=None, queued_at='2020-09-24T17:45:58.000+00:00')], run_number=160, pipeline_variable_list=[], block_run_details=[BlockRunDetail(block_id='1dab4f69-40fa-4285-aa28-1061ec96940b', block_run_id='c0fdf7f2-4762-4316-b333-2a7e29e3d11c', block_name='Train_1', technology='PYTHON', log_path=None, input_parameters='{}', output_parameters=None, status='READY_TO_GO', created_at='2020-09-24T17:45:58.032+00:00', queued_at='2020-09-24T17:45:58.000+00:00', start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[], resource_allocated=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))], pipeline_json='{\\n  \"id\": \"cd3d20ca-fe8d-11ea-ac5e-0242ac110005\",\\n  \"projectId\": \"c0b26d85-a4c9-44f5-9d0e-f540dd2de644\",\\n  \"name\": \"Train\",\\n  \"description\": \"\",\\n  \"blocks\": [\\n    {\\n      \"name\": \"Train_1\",\\n      \"id\": \"1dab4f69-40fa-4285-aa28-1061ec96940b\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"Train\",\\n      \"code\": \"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\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {},\\n      \"outputProperty\": {},\\n      \"resourceRequirement\": {\\n        \"cores\": 2,\\n        \"memory\": 20000,\\n        \"useGpu\": false,\\n        \"gpu\": 0,\\n        \"useGpuIfAvailable\": false,\\n        \"clusterConfiguration\": {\\n          \"worker\": null,\\n          \"workerCore\": null,\\n          \"workerMemory\": null,\\n          \"numberOfInstances\": null,\\n          \"maxServerCount\": null\\n        },\\n        \"additionalEnv\": {},\\n        \"runEnv\": \"PYTHON\"\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [\\n        {\\n          \"libraryId\": \"24d05fb2-8916-4d25-8127-276e57d0bc8d\",\\n          \"libraryVersionId\": \"67ceac05-426d-4c9a-a069-ceb1350c1623\"\\n        },\\n        {\\n          \"libraryId\": \"24d05fb2-8916-4d25-8127-276e57d0bc8d\",\\n          \"libraryVersionId\": \"67ceac05-426d-4c9a-a069-ceb1350c1623\"\\n        }\\n      ],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"process_id\": null,\\n      \"eta\": 0\\n    }\\n  ],\\n  \"connections\": [],\\n  \"priority\": \"LOW\",\\n  \"infraResourceEstimation\": null,\\n  \"resourceRequirement\": {\\n    \"cores\": null,\\n    \"memory\": null,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"comments\": null,\\n  \"order\": null,\\n  \"uiData\": null,\\n  \"dom\": null,\\n  \"systemGenerated\": false,\\n  \"systemModel\": false,\\n  \"pipelineVariableList\": [],\\n  \"pipelineTemplateVersion\": 0.0,\\n  \"versionId\": null,\\n  \"engineId\": \"65ed2499-f8c9-4c4d-ad27-aa689bd1531e\",\\n  \"userId\": \"c4080201-ccc9-4657-a457-7e18c100ff28\",\\n  \"runInitiatedFrom\": \"JUPYTER\",\\n  \"processList\": null,\\n  \"processInfo\": null\\n}', dom='Yet to add', order=None, infra_resource='{\\n  \"zookeeper\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"kafka\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  }\\n}', resource_spec=ResourceAllocated(cores=None, memory=None, use_gpu=None, gpu=None, use_gpu_if_available=None, cluster_configuration=None, additional_env={}, run_env=None), engine_id='65ed2499-f8c9-4c4d-ad27-aa689bd1531e', run_initiated_from='JUPYTER')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "\t<table width='100%'>\n",
       "\t\t<tr'><th>Slave Host</th><th>Type</th><th colspan='3' style='text-align: center;'>Usage</th></tr>\n",
       "\t\t<tbody>\n",
       "\t\t\t<tr><td>172.16.104.139 </td><td> INFRASTRUCTURE </td><td> CORE: Used 6 of 16 (37.5%)</td><td>RAM: Used 6.0 of 38.0GB (15.789473684210526%)</td></tr>\n",
       "\n",
       "\t\t\t<tr><td>172.16.114.99 </td><td> TECHNOLOGY </td><td> CORE: Used 21 of 32 (65.625%)</td><td>RAM: Used 36.53125 of 115.0GB (31.766304347826086%)</td></tr>\n",
       "\n",
       "\t\t</tbody>\n",
       "\t</table>\n",
       "</html>"
      ],
      "text/plain": [
       "PlatformEngineHealthList(slave_usage_array=[PlatformEngineHealth(server_ip='172.16.104.139', server_type='INFRASTRUCTURE', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=16, used=6, available=10, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=40802189312.0, used=6442450944.0, available=34359738368.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')]), PlatformEngineHealth(server_ip='172.16.114.99', server_type='TECHNOLOGY', server_usage_info=[ServerUsageInfo(label='Current cpu usage', graph_type='bar', unit='', total=32, used=21, available=11, value='CORE'), ServerUsageInfo(label='Current memory usage', graph_type='bar', unit='GB', total=123480309760.0, used=39225131008.0, available=84255178752.0, value='RAM'), ServerUsageInfo(label='Current gpu usage', graph_type='bar', unit='', total=0, used=0, available=0, value='GPU')])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-engine').health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <html>\n",
       "            <body>\n",
       "                <h4>Engine Queue</h4>\n",
       "                <h4>Number of queued blocks: 2</h4>\n",
       "                <table width='100%'>\n",
       "                <tr>\n",
       "                    <th style='align:left; text-align:left;'>Block</th>\n",
       "                    <th style='align:left; text-align:left;'>Pipeline</th>\n",
       "                    <th style='align:left; text-align:left;'>Wait Time(hours:minutes:seconds)</th>\n",
       "                </tr>\n",
       "        \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>performance_read</td>\n",
       "                    <td style='align:left; text-align:left;'>Pipeline_67</td>\n",
       "                    <td style='align:left; text-align:left;'>0:15:29</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td style='align:left; text-align:left;'>Train_1</td>\n",
       "                    <td style='align:left; text-align:left;'>Train</td>\n",
       "                    <td style='align:left; text-align:left;'>0:14:27</td>\n",
       "                </tr>\n",
       "            \n",
       "                </table>\n",
       "            </body>\n",
       "        </html>\n",
       "        "
      ],
      "text/plain": [
       "PlatformQueueStatusList(queue_list=[PlatformQueueStatus(block_run_id='a17482de-4cc8-4b37-ac37-013505bdc9f1', block_id='dba60f80-dc77-48b1-b090-b237e20bba1f', block_name='performance_read', pipeline_run_id='af36bc5a-fec9-4052-8bca-88600e8c2b7d', pipeline_id='587f2e00-fe41-11ea-b4c5-0242ac110009', pipeline_name='Pipeline_67', project_id='71e127b9-c19f-41e0-bb54-c9d98d160fe1', wait_time=929, published_by=RanByUser(user_name='Aneesh K', email='aneesh.k@razorthink.com'), resource_spec=ResourceAllocated(cores=1, memory=1024, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': 1, 'workerCore': 10, 'workerMemory': 10240, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={'SPARK_EXECUTOR_INSTANCES': '1', 'SPARK_EXECUTOR_CORES': '10', 'SPARK_EXECUTOR_MEMORY': '10g'}, run_env='PY_SPARK')), PlatformQueueStatus(block_run_id='0ed9da3a-a03f-4d41-a36d-c5e6e0e2aeab', block_id='6b0add15-75ba-46c7-b916-2a531591da35', block_name='Train_1', pipeline_run_id='1a339027-f161-4ebe-b2da-53448e91cb57', pipeline_id='829e3cbc-fe41-11ea-8def-0242ac110005', pipeline_name='Train', project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', wait_time=867, published_by=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), resource_spec=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "razor.api.engines('DS-engine').queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = razor.api.libraries(name='lightgbm').artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=config['cpu'], memory=config['ram']))\n",
    "class Infer:\n",
    "#     config: t.Any\n",
    "    \n",
    "    __libs__ = [lib1]\n",
    "    \n",
    "    def init(self):\n",
    "        self.VER = 1                          # Our model version\n",
    "        self.SEED = 42  \n",
    "        \n",
    "        #PATHS for Features\n",
    "        self.ORIGINAL = project_space_path(\"M5Forecasting\")+\"/\"\n",
    "        self.BASE     = project_space_path('M5Forecasting/m5-simple-fe/grid_part_1 .pkl')\n",
    "        self.PRICE    = project_space_path('M5Forecasting/m5-simple-fe/grid_part_2.pkl')\n",
    "        self.CALENDAR = project_space_path('M5Forecasting/m5-simple-fe/grid_part_3.pkl')\n",
    "        self.LAGS     = project_space_path('M5Forecasting/lags_df_28.pkl')\n",
    "        self.MEAN_ENC = project_space_path('M5Forecasting/mean_encoding_df.pkl')\n",
    "\n",
    "        #LIMITS and const\n",
    "        self.TARGET      = 'sales'            # Our target\n",
    "        self.START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "        self.END_TRAIN   = 1913               # End day of our train set\n",
    "        self.P_HORIZON   = 28                 # Prediction horizon\n",
    "        self.USE_AUX     = False               # Use or not pretrained models\n",
    "        self.N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "        # AUX(pretrained) Models paths\n",
    "        self.AUX_MODELS = './M5Forecasting/m5-aux-models/'\n",
    "\n",
    "\n",
    "        #STORES ids\n",
    "        self.STORES_IDS = pd.read_csv(self.ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "        self.STORES_IDS = list(self.STORES_IDS.unique())\n",
    "\n",
    "\n",
    "        #SPLITS for lags creation\n",
    "        self.SHIFT_DAY  = 28\n",
    "        self.N_LAGS     = 15\n",
    "        self.LAGS_SPLIT = [col for col in range(self.SHIFT_DAY, self.SHIFT_DAY + self.N_LAGS)]\n",
    "        \n",
    "        self.remove_features = ['id','state_id','store_id',\n",
    "                           'date','wm_yr_wk','d', self.TARGET]\n",
    "        self.mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                           'enc_dept_id_mean','enc_dept_id_std',\n",
    "                           'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "            \n",
    "    def seed_everything(self, seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    ## Multiprocess Runs\n",
    "    def df_parallelize_run(self, func, t_split):\n",
    "        num_cores = np.min([self.N_CORES,len(t_split)])\n",
    "        pool = Pool(num_cores)\n",
    "        df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "\n",
    "    def get_data_by_store(self, store):\n",
    "\n",
    "        # Read and contact basic feature\n",
    "        df1 = pd.read_pickle(self.BASE)\n",
    "#         df1 = df1[df1['store_id']==store]\n",
    "        df2 = pd.read_pickle(self.PRICE).iloc[:,2:]\n",
    "#         df2 = df2[df2['store_id']==store]\n",
    "        df3 = pd.read_pickle(self.CALENDAR).iloc[:,2:]\n",
    "        df = pd.concat([df1, df2, df3],\n",
    "                        axis=1)\n",
    "\n",
    "        # Leave only relevant store\n",
    "        df = df[df['store_id']==store]\n",
    "\n",
    "        # With memory limits we have to read \n",
    "        # lags and mean encoding features\n",
    "        # separately and drop items that we don't need.\n",
    "        # As our Features Grids are aligned \n",
    "        # we can use index to keep only necessary rows\n",
    "        # Alignment is good for us as concat uses less memory than merge.\n",
    "        df2 = pd.read_pickle(self.MEAN_ENC)[self.mean_features]\n",
    "        df2 = df2[df2.index.isin(df.index)]\n",
    "\n",
    "        df = pd.concat([df, df2], axis=1)\n",
    "        del df2 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        df3 = pd.read_pickle(self.LAGS).iloc[:,3:]\n",
    "        df3 = df3[df3.index.isin(df.index)]\n",
    "\n",
    "\n",
    "        df = pd.concat([df, df3], axis=1)\n",
    "        del df3 # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        # Create features list\n",
    "        features = [col for col in list(df) if col not in self.remove_features]\n",
    "        \n",
    "        del df # to not reach memory limit \n",
    "        gc.collect()\n",
    "\n",
    "        return features\n",
    "\n",
    "    # Recombine Test set after training\n",
    "    def get_base_test(self):\n",
    "        base_test = pd.DataFrame()\n",
    "\n",
    "        for store_id in self.STORES_IDS:\n",
    "            temp_df = pd.read_pickle(project_space_path('M5Forecasting/test_'+store_id+'.pkl'))\n",
    "            temp_df['store_id'] = store_id\n",
    "            base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "\n",
    "        return base_test\n",
    "\n",
    "\n",
    "    ########################### Helper to make dynamic rolling lags\n",
    "    #################################################################################\n",
    "    def make_lag(self, LAG_DAY):\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'sales_lag_{str(LAG_DAY)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "        return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "    def make_lag_roll(self, LAG_DAY):\n",
    "        shift_day = LAG_DAY[0]\n",
    "        roll_wind = LAG_DAY[1]\n",
    "        lag_df = base_test[['id','d',self.TARGET]]\n",
    "        col_name = f'rolling_mean_tmp_{str(shift_day)}_{str(roll_wind)}'\n",
    "        lag_df[col_name] = lag_df.groupby(['id'])[self.TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "        return lag_df[[col_name]]\n",
    "    \n",
    "    def run(self):\n",
    "        ########################### Predict\n",
    "        #################################################################################\n",
    "\n",
    "        # Create Dummy DataFrame to store predictions\n",
    "        all_preds = pd.DataFrame()\n",
    "\n",
    "        # Join back the Test dataset with \n",
    "        # a small part of the training data \n",
    "        # to make recursive features\n",
    "        base_test = self.get_base_test()\n",
    "\n",
    "        # Timer to measure predictions time \n",
    "        main_time = time.time()\n",
    "\n",
    "        ROLS_SPLIT = []\n",
    "\n",
    "        for i in [1,7,14]:\n",
    "            for j in [7,14,30,60]:\n",
    "                ROLS_SPLIT.append([i,j])\n",
    "\n",
    "        # Loop over each prediction day\n",
    "        # As rolling lags are the most timeconsuming\n",
    "        # we will calculate it for whole day\n",
    "        for PREDICT_DAY in range(1,29):    \n",
    "            print('Predict | Day:', PREDICT_DAY)\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Make temporary grid to calculate rolling lags\n",
    "            grid_df = base_test.copy()\n",
    "            grid_df = pd.concat([grid_df, self.df_parallelize_run(self.make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "\n",
    "            for store_id in self.STORES_IDS:\n",
    "\n",
    "                # Read all our models and make predictions\n",
    "                # for each day/store pairs\n",
    "                model_path = project_space_path('M5Forecasting/lgb_model_'+store_id+'_v'+str(VER)+'.bin') \n",
    "                if USE_AUX:\n",
    "                    model_path = self.AUX_MODELS + model_path\n",
    "\n",
    "                estimator = pickle.load(open(model_path, 'rb'))\n",
    "\n",
    "                day_mask = base_test['d']==(self.END_TRAIN+self.PREDICT_DAY)\n",
    "                store_mask = base_test['store_id']==store_id\n",
    "\n",
    "                mask = (day_mask)&(store_mask)\n",
    "                MODEL_FEATURES = self.get_data_by_store(store_id)\n",
    "                base_test[self.TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "\n",
    "            # Make good column naming and add \n",
    "            # to all_preds DataFrame\n",
    "            temp_df = base_test[day_mask][['id',TARGET]]\n",
    "            temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "            if 'id' in list(all_preds):\n",
    "                all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "            else:\n",
    "                all_preds = temp_df.copy()\n",
    "\n",
    "            print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                          ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                          ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "            del temp_df\n",
    "\n",
    "        all_preds = all_preds.reset_index(drop=True)\n",
    "\n",
    "        submission = pd.read_csv(self.ORIGINAL+'sample_submission_accuracy.csv')[['id']]\n",
    "        submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "        submission.to_csv(self.ORIGINAL+'submission_v'+str(VER)+'.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = Infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rf.Pipeline(\"Infer\", targets=[infer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.run+monitor+json": "/home/jovyan/logs/19b31ec0-d548-4761-9ec1-c397447944bd",
      "text/plain": [
       "<razor_tools.backend.ipython.mime.run_monitor.RunMonitor at 0x7f9352aad910>"
      ]
     },
     "metadata": {
      "application/vnd.razorthink.run+monitor+json": {
       "store_in_notebook": false
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "PlatformPipelineRun(project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', pipeline_id='4ced450a-ff1c-11ea-bf47-0242ac11000d', pipeline_name='Train', pipeline_run_id='19b31ec0-d548-4761-9ec1-c397447944bd', pipeline_version=None, comment=None, created_on='2020-09-25T10:46:00.625+00:00', start_time=None, end_time=None, eta=0, run_at=1601030760625, run_duration=0, compute_time=0, wait_time=130, ran_by_user=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), status='IN_PROGRESS', block_status=[PlatformPipelineBlockRun(pipeline_run_id='19b31ec0-d548-4761-9ec1-c397447944bd', pipeline_name='Train', pipeline_status='IN_PROGRESS', block_id='867f51eb-184d-4fa9-ba0d-5aab4ed29359', block_run_id='874de4be-d10d-4cce-92f6-dae85307202e', block_name='Infer_1', resource_spec=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'), technology='PYTHON', status='READY_TO_GO', containers=[], cluster_id='867f51eb-184d-4fa9-ba0d-5aab4ed29359', _log=None, _metric=None, wait_time=0, compute_time=0, start_time=None, end_time=None, queued_at='2020-09-25T10:46:01.000+00:00')], run_number=164, pipeline_variable_list=[], block_run_details=[BlockRunDetail(block_id='867f51eb-184d-4fa9-ba0d-5aab4ed29359', block_run_id='874de4be-d10d-4cce-92f6-dae85307202e', block_name='Infer_1', technology='PYTHON', log_path=None, input_parameters='{}', output_parameters=None, status='READY_TO_GO', created_at='2020-09-25T10:46:00.732+00:00', queued_at='2020-09-25T10:46:01.000+00:00', start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[], resource_allocated=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))], pipeline_json='{\\n  \"id\": \"4ced450a-ff1c-11ea-bf47-0242ac11000d\",\\n  \"projectId\": \"c0b26d85-a4c9-44f5-9d0e-f540dd2de644\",\\n  \"name\": \"Train\",\\n  \"description\": \"\",\\n  \"blocks\": [\\n    {\\n      \"name\": \"Infer_1\",\\n      \"id\": \"867f51eb-184d-4fa9-ba0d-5aab4ed29359\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"Infer\",\\n      \"code\": \"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\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {},\\n      \"outputProperty\": {},\\n      \"resourceRequirement\": {\\n        \"cores\": 2,\\n        \"memory\": 20000,\\n        \"useGpu\": false,\\n        \"gpu\": 0,\\n        \"useGpuIfAvailable\": false,\\n        \"clusterConfiguration\": {\\n          \"worker\": null,\\n          \"workerCore\": null,\\n          \"workerMemory\": null,\\n          \"numberOfInstances\": null,\\n          \"maxServerCount\": null\\n        },\\n        \"additionalEnv\": {},\\n        \"runEnv\": \"PYTHON\"\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [\\n        {\\n          \"libraryId\": \"24d05fb2-8916-4d25-8127-276e57d0bc8d\",\\n          \"libraryVersionId\": \"67ceac05-426d-4c9a-a069-ceb1350c1623\"\\n        },\\n        {\\n          \"libraryId\": \"24d05fb2-8916-4d25-8127-276e57d0bc8d\",\\n          \"libraryVersionId\": \"67ceac05-426d-4c9a-a069-ceb1350c1623\"\\n        }\\n      ],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"process_id\": null,\\n      \"eta\": 0\\n    }\\n  ],\\n  \"connections\": [],\\n  \"priority\": \"LOW\",\\n  \"infraResourceEstimation\": null,\\n  \"resourceRequirement\": {\\n    \"cores\": null,\\n    \"memory\": null,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"comments\": null,\\n  \"order\": null,\\n  \"uiData\": null,\\n  \"dom\": null,\\n  \"systemGenerated\": false,\\n  \"systemModel\": false,\\n  \"pipelineVariableList\": [],\\n  \"pipelineTemplateVersion\": 0.0,\\n  \"versionId\": null,\\n  \"engineId\": \"65ed2499-f8c9-4c4d-ad27-aa689bd1531e\",\\n  \"userId\": \"c4080201-ccc9-4657-a457-7e18c100ff28\",\\n  \"runInitiatedFrom\": \"JUPYTER\",\\n  \"processList\": null,\\n  \"processInfo\": null\\n}', dom='Yet to add', order=None, infra_resource='{\\n  \"zookeeper\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"kafka\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  }\\n}', resource_spec=ResourceAllocated(cores=None, memory=None, use_gpu=None, gpu=None, use_gpu_if_available=None, cluster_configuration=None, additional_env={}, run_env=None), engine_id='65ed2499-f8c9-4c4d-ad27-aa689bd1531e', run_initiated_from='JUPYTER')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
