{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "import logging\n",
    "from razor.api import project_space_path\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razor.api import project_space_path\n",
    "import razor\n",
    "from razor import Technology, LibraryMode\n",
    "import razor.flow as rf\n",
    "import typing as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=3000))\n",
    "class Configs:\n",
    "    config: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        dic = {\n",
    "          \"TARGET\": \"sales\",\n",
    "          \"END_TRAIN\": 1913,\n",
    "          \"MAIN_INDEX\": [\n",
    "            \"id\",\n",
    "            \"d\"\n",
    "          ],\n",
    "          'index_columns' : ['id','item_id','dept_id','cat_id','store_id','state_id'],\n",
    "          \"train_path\": \"M5Forecasting/sales_train_validation.csv\",\n",
    "          \"prices_path\": \"M5Forecasting/sell_prices.csv\",\n",
    "          \"calendar_path\" : \"M5Forecasting/calendar.csv\"\n",
    "        }\n",
    "        self.config.put(dic)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = Configs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging by concat to not lose dtypes\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1913         # Last day in train set\n",
    "MAIN_INDEX = ['id','d']  # We can identify item by these columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Main Data\n"
     ]
    }
   ],
   "source": [
    "print('Load Main Data')\n",
    "\n",
    "# Here are reafing all our data \n",
    "# without any limitations and dtype modification\n",
    "train_df = pd.read_csv(project_space_path('M5Forecasting/sales_train_validation.csv'))\n",
    "prices_df = pd.read_csv(project_space_path('M5Forecasting/sell_prices.csv'))\n",
    "calendar_df = pd.read_csv(project_space_path('M5Forecasting/calendar.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(project_space_path('M5Forecasting/train_df.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=8192))\n",
    "class Melter:\n",
    "    path: t.Any\n",
    "    grid_df_path: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        train_df=pd.read_csv(project_space_path(self.path))\n",
    "        print('Create Grid')\n",
    "\n",
    "        # We can tranform horizontal representation \n",
    "        # to vertical \"view\"\n",
    "        # Our \"index\" will be 'id','item_id','dept_id','cat_id','store_id','state_id'\n",
    "        # and labels are 'd_' coulmns\n",
    "\n",
    "        index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "        df = pd.melt(train_df, \n",
    "                          id_vars = index_columns, \n",
    "                          var_name = 'd', \n",
    "                          value_name = TARGET)\n",
    "        \n",
    "        df.to_csv(project_space_path('M5Forecasting/grid_df.csv'), index=False)\n",
    "        self.grid_df_path.put('M5Forecasting/grid_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "melter = Melter(path='M5Forecasting/train_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = rf.Pipeline(\"Melting\", targets=[melter])  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=8192))\n",
    "class HeavyOp1:\n",
    "    path: t.Any\n",
    "    config: t.Any\n",
    "    add_grid_path: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "            \n",
    "    def run(self):\n",
    "        import pandas as pd\n",
    "        import logging\n",
    "        \n",
    "        self.logger.info(\"Reading df\")\n",
    "        train_df=pd.read_csv(project_space_path(self.path))\n",
    "        self.logger.info(\"Reading df DONE...\")\n",
    "        \n",
    "        END_TRAIN = self.config[\"END_TRAIN\"]\n",
    "        TARGET = self.config[\"TARGET\"]\n",
    "        # If we look on train_df we se that \n",
    "        # we don't have a lot of traning rows\n",
    "        # but each day can provide more train data\n",
    "        print('Train rows:', len(train_df))\n",
    "\n",
    "        # To be able to make predictions\n",
    "        # we need to add \"test set\" to our grid\n",
    "        index_columns = self.config['index_columns']\n",
    "        df = pd.DataFrame()\n",
    "        for i in range(1,29):\n",
    "            temp_df = train_df[index_columns]\n",
    "            temp_df = temp_df.drop_duplicates()\n",
    "            temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n",
    "            temp_df[TARGET] = np.nan\n",
    "            df = pd.concat([df,temp_df])\n",
    "            \n",
    "        df.to_csv(project_space_path('M5Forecasting/add_grid.csv'), index=False)\n",
    "        self.add_grid_path.put('M5Forecasting/add_grid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_op1 = HeavyOp1(path='M5Forecasting/train_df.csv', config=configs.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = rf.Pipeline(\"heavy_op1\", targets=[heavy_op1], env=Technology.PYTHON)  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=13000))\n",
    "class HeavyOp2:\n",
    "    grid_df_path: t.Any\n",
    "    add_grid_path: t.Any    \n",
    "    config: t.Any    \n",
    "    grid_df_int_path: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        def sizeof_fmt(num, suffix='B'):\n",
    "            for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "                if abs(num) < 1024.0:\n",
    "                    return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "                num /= 1024.0\n",
    "            return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "        \n",
    "        \n",
    "        grid_df = pd.read_csv(project_space_path(self.grid_df_path))\n",
    "        add_grid = pd.read_csv(project_space_path(self.add_grid_path))\n",
    "\n",
    "        grid_df = pd.concat([grid_df,add_grid])\n",
    "        grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # Let's check our memory usage\n",
    "        self.logger.info(\"{:>20}: {:>8}\".format('Original grid_df', sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "        # We can free some memory \n",
    "        # by converting \"strings\" to categorical\n",
    "        # it will not affect merging and \n",
    "        # we will not lose any valuable data\n",
    "        index_columns = self.config['index_columns']\n",
    "        for col in index_columns:\n",
    "            grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "        # Let's check again memory usage\n",
    "        self.logger.info(\"{:>20}: {:>8}\".format('Reduced grid_df', sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "        grid_df.to_csv(project_space_path('M5Forecasting/grid_df_int.csv'))\n",
    "        self.grid_df_int_path.put('M5Forecasting/grid_df_int.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_op2 = HeavyOp2(config=configs.config, add_grid_path=heavy_op1.add_grid_path, grid_df_path=melter.grid_df_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = rf.Pipeline(\"heavy_op2\", targets=[heavy_op2])  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=20000))\n",
    "class HeavyOp3:\n",
    "    grid_df_path: t.Any\n",
    "    config: t.Any\n",
    "    grid_pkl_path: rf.Output[t.Any] = rf.Output(transport=rf.FileTransport)\n",
    "    \n",
    "    \n",
    "    def sizeof_fmt(self, num, suffix='B'):\n",
    "        for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "            if abs(num) < 1024.0:\n",
    "                return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "            num /= 1024.0\n",
    "        return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "    def merge_by_concat(self, df1, df2, merge_on):\n",
    "        merged_gf = df1[merge_on]\n",
    "        merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "        new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "        df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "        return df1\n",
    "    \n",
    "    def run(self):\n",
    "        from razor.api import project_space_path\n",
    "        \n",
    "        prices_df = pd.read_csv(project_space_path(self.config['prices_path']))\n",
    "        grid_df = pd.read_csv(project_space_path(self.grid_df_path))\n",
    "        calendar_df = pd.read_csv(project_space_path(self.config['calendar_path']))\n",
    "        # Prices are set by week\n",
    "        # so it we will have not very accurate release week \n",
    "        release_df = prices_df.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "        release_df.columns = ['store_id','item_id','release']\n",
    "        self.logger.info('Release Df')\n",
    "        self.logger.info(release_df.head())\n",
    "        \n",
    "        self.logger.info('Release week')\n",
    "        # Now we can merge release_df\n",
    "        grid_df = self.merge_by_concat(grid_df, release_df, ['store_id','item_id'])\n",
    "        del release_df\n",
    "\n",
    "\n",
    "        grid_df = self.merge_by_concat(grid_df, calendar_df[['wm_yr_wk','d']], ['d'])\n",
    "\n",
    "        # Now we can cutoff some rows \n",
    "        # and safe memory \n",
    "        grid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\n",
    "        grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "        # Let's check our memory usage\n",
    "        self.logger.info(\"{:>20}: {:>8}\".format('Original grid_df',self.sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "        grid_df['release'] = grid_df['release'] - grid_df['release'].min()\n",
    "        grid_df['release'] = grid_df['release'].astype(np.int16)\n",
    "\n",
    "        # Let's check again memory usage\n",
    "        self.logger.info(\"{:>20}: {:>8}\".format('Reduced grid_df',self.sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "        grid_df = grid_df.drop(['Unnamed: 0'], 1)\n",
    "#         grid_df.to_pickle(project_space_path('M5Forecasting/m5-simple-fe/grid_part_1.pkl'))\n",
    "        self.logger.info(grid_df.shape)\n",
    "        grid_df.to_pickle(project_space_path('M5Forecasting/debug/grid_part_1.pkl'))\n",
    "        grid_df.to_csv(project_space_path('M5Forecasting/grid_df_final.csv'))\n",
    "        self.grid_pkl_path.put('M5Forecasting/debug/grid_part_1.pkl')\n",
    "                       \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavy_op3 = HeavyOp3(config=configs.config, grid_df_path=heavy_op2.grid_df_int_path)\n",
    "heavy_op3 = HeavyOp3(config=configs.config, grid_df_path='M5Forecasting/grid_df_int.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=20000))\n",
    "class HeavyOp4:\n",
    "    grid_path: t.Any\n",
    "    config: t.Any\n",
    "        \n",
    "        \n",
    "    def sizeof_fmt(self, num, suffix='B'):\n",
    "            for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "                if abs(num) < 1024.0:\n",
    "                    return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "                num /= 1024.0\n",
    "            return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "        \n",
    "    def merge_by_concat(self, df1, df2, merge_on):\n",
    "        merged_gf = df1[merge_on]\n",
    "        merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "        new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "        df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "        return df1\n",
    "\n",
    "    def reduce_mem_usage(self, df, verbose=True):\n",
    "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "        start_mem = df.memory_usage().sum() / 1024**2    \n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtypes\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                           df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)    \n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "        if verbose: \n",
    "            print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def run(self):\n",
    "        from razor.api import project_space_path\n",
    "\n",
    "        prices_df=pd.read_csv(project_space_path(self.config[\"prices_path\"]))\n",
    "        calendar_df=pd.read_csv(project_space_path(self.config[\"calendar_path\"]))\n",
    "        \n",
    "        self.logger.info('Release week')\n",
    "        \n",
    "        self.logger.info('Prices')\n",
    "\n",
    "        # We can do some basic aggregations\n",
    "        prices_df['price_max'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n",
    "        prices_df['price_min'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "        prices_df['price_std'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n",
    "        prices_df['price_mean'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n",
    "\n",
    "        # and do price normalization (min/max scaling)\n",
    "        prices_df['price_norm'] = prices_df['sell_price']/prices_df['price_max']\n",
    "\n",
    "        # Some items are can be inflation dependent\n",
    "        # and some items are very \"stable\"\n",
    "        prices_df['price_nunique'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique')\n",
    "        prices_df['item_nunique'] = prices_df.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n",
    "\n",
    "        # I would like some \"rolling\" aggregations\n",
    "        # but would like months and years as \"window\"\n",
    "        calendar_prices = calendar_df[['wm_yr_wk','month','year']]\n",
    "        calendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk'])\n",
    "        prices_df = prices_df.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')\n",
    "        del calendar_prices\n",
    "\n",
    "        # Now we can add price \"momentum\" (some sort of)\n",
    "        # Shifted by week \n",
    "        # by month mean\n",
    "        # by year mean\n",
    "        prices_df['price_momentum'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "        prices_df['price_momentum_m'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "        prices_df['price_momentum_y'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n",
    "\n",
    "        del prices_df['month'], prices_df['year']\n",
    "        \n",
    "        ########################## Merge prices and save part 2\n",
    "        #################################################################################\n",
    "        self.logger.info('Merge prices and save part 2')\n",
    "\n",
    "        grid_df = pd.read_pickle(project_space_path(self.grid_path))\n",
    "        MAIN_INDEX=self.config[\"MAIN_INDEX\"]\n",
    "        \n",
    "        # Merge Prices\n",
    "        original_columns = list(grid_df)\n",
    "        grid_df = grid_df.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "        keep_columns = [col for col in list(grid_df) if col not in original_columns]\n",
    "        grid_df = grid_df[MAIN_INDEX+keep_columns]\n",
    "        grid_df = self.reduce_mem_usage(grid_df)\n",
    "\n",
    "        # Safe part 2\n",
    "        grid_df.to_pickle(project_space_path('M5Forecasting/debug/grid_part_2.pkl'))\n",
    "        self.logger.info(f'Size: {grid_df.shape}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_op4 = HeavyOp4(config=configs.config, grid_path=heavy_op3.grid_pkl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = rf.Pipeline(\"heavy_op4\", targets=[heavy_op4])  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rf.block(executor=rf.ContainerExecutor(cores=2, memory=20000))\n",
    "class HeavyOp5:\n",
    "    grid_path: t.Any\n",
    "    config: t.Any\n",
    "       \n",
    "    \n",
    "    def sizeof_fmt(self, num, suffix='B'):\n",
    "        for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "            if abs(num) < 1024.0:\n",
    "                return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "            num /= 1024.0\n",
    "        return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "    def merge_by_concat(self, df1, df2, merge_on):\n",
    "        merged_gf = df1[merge_on]\n",
    "        merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "        new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "        df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "        return df1\n",
    "    \n",
    "    def run(self):\n",
    "        from razor.api import project_space_path\n",
    "        \n",
    "        calendar_df=pd.read_csv(project_space_path(self.config[\"calendar_path\"]))\n",
    "        grid_df = pd.read_pickle(project_space_path(self.grid_path))\n",
    "        MAIN_INDEX=self.config[\"MAIN_INDEX\"]\n",
    "        \n",
    "        ########################### Merge calendar\n",
    "        #################################################################################\n",
    "        grid_df = grid_df[MAIN_INDEX]\n",
    "\n",
    "        # Merge calendar partly\n",
    "        icols = ['date',\n",
    "                 'd',\n",
    "                 'event_name_1',\n",
    "                 'event_type_1',\n",
    "                 'event_name_2',\n",
    "                 'event_type_2',\n",
    "                 'snap_CA',\n",
    "                 'snap_TX',\n",
    "                 'snap_WI']\n",
    "\n",
    "        grid_df = grid_df.merge(calendar_df[icols], on=['d'], how='left')\n",
    "\n",
    "        # Minify data\n",
    "        # 'snap_' columns we can convert to bool or int8\n",
    "        icols = ['event_name_1',\n",
    "                 'event_type_1',\n",
    "                 'event_name_2',\n",
    "                 'event_type_2',\n",
    "                 'snap_CA',\n",
    "                 'snap_TX',\n",
    "                 'snap_WI']\n",
    "        for col in icols:\n",
    "            grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "        # Convert to DateTime\n",
    "        grid_df['date'] = pd.to_datetime(grid_df['date'])\n",
    "\n",
    "        # Make some features from date\n",
    "        grid_df['tm_d'] = grid_df['date'].dt.day.astype(np.int8)\n",
    "        grid_df['tm_w'] = grid_df['date'].dt.week.astype(np.int8)\n",
    "        grid_df['tm_m'] = grid_df['date'].dt.month.astype(np.int8)\n",
    "        grid_df['tm_y'] = grid_df['date'].dt.year\n",
    "        grid_df['tm_y'] = (grid_df['tm_y'] - grid_df['tm_y'].min()).astype(np.int8)\n",
    "        grid_df['tm_wm'] = grid_df['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int8)\n",
    "\n",
    "        grid_df['tm_dw'] = grid_df['date'].dt.dayofweek.astype(np.int8)\n",
    "        grid_df['tm_w_end'] = (grid_df['tm_dw']>=5).astype(np.int8)\n",
    "\n",
    "        # Remove date\n",
    "        del grid_df['date']\n",
    "        ########################### Save part 3 (Dates)\n",
    "        #################################################################################\n",
    "        print('Save part 3')\n",
    "\n",
    "        # Safe part 3\n",
    "        grid_df.to_pickle(project_space_path('M5Forecasting/debug/grid_part_3.pkl'))\n",
    "        print('Size:', grid_df.shape)\n",
    "\n",
    "        # We don't need calendar_df anymore\n",
    "        del calendar_df\n",
    "        del grid_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_op5 = HeavyOp5(config=configs.config, grid_path=heavy_op3.grid_pkl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = rf.Pipeline(\"heavy_op3\", targets=[heavy_op3])  #preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.interactive+pipeline+view+json": {
       "blocks": [
        {
         "class_name": "HeavyOp3",
         "id": "fa9deae6-177f-4dec-b3d6-5c65aab37c8e",
         "inputs": [
          {
           "default": null,
           "flow": "atomic",
           "help": null,
           "label": "grid_df_path",
           "name": "grid_df_path",
           "series": false,
           "type": "Any",
           "type_check": true
          },
          {
           "default": null,
           "flow": "atomic",
           "help": null,
           "label": "config",
           "name": "config",
           "series": false,
           "type": "Any",
           "type_check": true
          }
         ],
         "outputs": [
          {
           "flow": "atomic",
           "help": null,
           "label": "grid_pkl_path",
           "name": "grid_pkl_path",
           "series": false,
           "type": "Any",
           "type_check": true
          }
         ],
         "overwritten": false,
         "var_names": [
          "HeavyOp3"
         ]
        },
        {
         "class_name": "Configs",
         "id": "fc313d50-b65d-466e-946d-27a6d3beb3d0",
         "inputs": [],
         "outputs": [
          {
           "flow": "atomic",
           "help": null,
           "label": "config",
           "name": "config",
           "series": false,
           "type": "Any",
           "type_check": true
          }
         ],
         "overwritten": false,
         "var_names": [
          "Configs"
         ]
        }
       ],
       "connections": [
        {
         "id": "11684bc5-08de-404e-84bb-f87305d3d533",
         "source": {
          "adapter": false,
          "instance_id": "3115c549-05d2-419c-a80c-8b1d87a27ffc",
          "name": "config"
         },
         "target": {
          "adapter": false,
          "instance_id": "4f3eb8be-6110-48c4-9859-9d10469f1280",
          "name": "config"
         }
        }
       ],
       "id": "03f85404-3493-4d37-ac9d-3c697e3e615a",
       "instances": [
        {
         "block_class": "fa9deae6-177f-4dec-b3d6-5c65aab37c8e",
         "id": "4f3eb8be-6110-48c4-9859-9d10469f1280",
         "name": "HeavyOp3_1",
         "var_names": [
          "heavy_op3"
         ]
        },
        {
         "block_class": "fc313d50-b65d-466e-946d-27a6d3beb3d0",
         "id": "3115c549-05d2-419c-a80c-8b1d87a27ffc",
         "name": "Configs_1",
         "var_names": [
          "configs"
         ]
        }
       ],
       "name": "heavy_op3",
       "var_names": []
      },
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"176pt\" height=\"127pt\"\n",
       " viewBox=\"0.00 0.00 176.36 127.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 123)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-123 172.3576,-123 172.3576,4 -4,4\"/>\n",
       "<!-- HeavyOp3(&#39;HeavyOp3_1&#39;) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>HeavyOp3(&#39;HeavyOp3_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"84.1788\" cy=\"-18\" rx=\"84.358\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.1788\" y=\"-15.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#000000\">HeavyOp3(&#39;HeavyOp3_1&#39;)</text>\n",
       "</g>\n",
       "<!-- Configs(&#39;Configs_1&#39;) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Configs(&#39;Configs_1&#39;)</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"84.1788\" cy=\"-101\" rx=\"66.5378\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.1788\" y=\"-98.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#000000\">Configs(&#39;Configs_1&#39;)</text>\n",
       "</g>\n",
       "<!-- Configs(&#39;Configs_1&#39;)&#45;&gt;HeavyOp3(&#39;HeavyOp3_1&#39;) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Configs(&#39;Configs_1&#39;)&#45;&gt;HeavyOp3(&#39;HeavyOp3_1&#39;)</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M84.1788,-82.9902C84.1788,-72.2963 84.1788,-58.4994 84.1788,-46.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.6789,-46.2612 84.1788,-36.2612 80.6789,-46.2613 87.6789,-46.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.6788\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#000000\">config&#45;&gt;config</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<razor.flow.pipeline.Pipeline at 0x7fc58cb49bd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_pipeline = razor.api.engines('DS-engine').execute(pipeline=p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.razorthink.run+monitor+json": "/home/jovyan/logs/aaed2ba4-6be2-4f45-8fb3-d1a7b00a016d",
      "text/plain": [
       "<razor_tools.backend.ipython.mime.run_monitor.RunMonitor at 0x7fc58c276310>"
      ]
     },
     "metadata": {
      "application/vnd.razorthink.run+monitor+json": {
       "store_in_notebook": false
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "PlatformPipelineRun(project_id='c0b26d85-a4c9-44f5-9d0e-f540dd2de644', pipeline_id='792a056e-0560-11eb-92e0-0242ac110004', pipeline_name='heavy_op3', pipeline_run_id='aaed2ba4-6be2-4f45-8fb3-d1a7b00a016d', pipeline_version=None, comment=None, created_on='2020-10-03T10:09:08.897+00:00', start_time=None, end_time=None, eta=0, run_at=1601719748897, run_duration=0, compute_time=0, wait_time=567, ran_by_user=RanByUser(user_name='Ayan Basak', email='ayan.basak@razorthink.com'), status='IN_PROGRESS', block_status=[PlatformPipelineBlockRun(pipeline_run_id='aaed2ba4-6be2-4f45-8fb3-d1a7b00a016d', pipeline_name='heavy_op3', pipeline_status='IN_PROGRESS', block_id='2a5f536f-20e5-4dc9-a284-adc66882bcb2', block_run_id='74d129d8-a6b8-4ea2-ba8e-f2ac6fefb1d8', block_name='Configs_1', resource_spec=ResourceAllocated(cores=2, memory=3000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'), technology='PYTHON', status='READY_TO_GO', containers=[], cluster_id='2a5f536f-20e5-4dc9-a284-adc66882bcb2', _log=None, _metric=None, wait_time=0, compute_time=0, start_time=None, end_time=None, queued_at='2020-10-03T10:09:09.000+00:00'), PlatformPipelineBlockRun(pipeline_run_id='aaed2ba4-6be2-4f45-8fb3-d1a7b00a016d', pipeline_name='heavy_op3', pipeline_status='IN_PROGRESS', block_id='4951e7f5-57c8-465f-8bbc-c3cadf6ce0d0', block_run_id='bc610ff8-ab70-460c-b133-9c8be3181bbd', block_name='HeavyOp3_1', resource_spec=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'), technology='PYTHON', status='YET_TO_START', containers=[], cluster_id='4951e7f5-57c8-465f-8bbc-c3cadf6ce0d0', _log=None, _metric=None, wait_time=0, compute_time=0, start_time=None, end_time=None, queued_at=None)], run_number=227, pipeline_variable_list=[], block_run_details=[BlockRunDetail(block_id='2a5f536f-20e5-4dc9-a284-adc66882bcb2', block_run_id='74d129d8-a6b8-4ea2-ba8e-f2ac6fefb1d8', block_name='Configs_1', technology='PYTHON', log_path=None, input_parameters='{}', output_parameters=None, status='READY_TO_GO', created_at='2020-10-03T10:09:09.012+00:00', queued_at='2020-10-03T10:09:09.000+00:00', start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[BlockRunOutputList(output_id='900fe96c-579a-4097-bd63-68450cdda489', output_name='config', created_on='2020-10-03T10:09:09.217+00:00', output_status='YET_TO_START', block_transport='FILE')], resource_allocated=ResourceAllocated(cores=2, memory=3000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON')), BlockRunDetail(block_id='4951e7f5-57c8-465f-8bbc-c3cadf6ce0d0', block_run_id='bc610ff8-ab70-460c-b133-9c8be3181bbd', block_name='HeavyOp3_1', technology='PYTHON', log_path=None, input_parameters=None, output_parameters=None, status='YET_TO_START', created_at='2020-10-03T10:09:09.227+00:00', queued_at=None, start_time=None, end_time=None, compute_time=0, wait_time=0, run_time=0, block_run_output_list=[], resource_allocated=ResourceAllocated(cores=2, memory=20000, use_gpu=False, gpu=0, use_gpu_if_available=False, cluster_configuration={'worker': None, 'workerCore': None, 'workerMemory': None, 'numberOfInstances': None, 'maxServerCount': None}, additional_env={}, run_env='PYTHON'))], pipeline_json='{\\n  \"id\": \"792a056e-0560-11eb-92e0-0242ac110004\",\\n  \"projectId\": \"c0b26d85-a4c9-44f5-9d0e-f540dd2de644\",\\n  \"name\": \"heavy_op3\",\\n  \"description\": \"\",\\n  \"blocks\": [\\n    {\\n      \"name\": \"HeavyOp3_1\",\\n      \"id\": \"4951e7f5-57c8-465f-8bbc-c3cadf6ce0d0\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"HeavyOp3\",\\n      \"code\": \"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\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {\\n        \"grid_df_path\": {\\n          \"dtype\": \"Any\",\\n          \"required\": \"false\",\\n          \"series\": false,\\n          \"adapter\": \"eJxrYJmqxgABPYJFiVX5RXppOfnlern5Kak5xVN6ePLy8wviE1MSC0pSi6ZMnqIHAF/+ELQ=\",\\n          \"validator\": \"eJxrYJmqwQABPYJFiVX5RXppOfnlern5Kak5xVN6+PLy8wviyxJzMlMSS/KLpkyeogcAg2wRnQ==\",\\n          \"source_id\": null,\\n          \"source_name\": null,\\n          \"inferred_type\": \"STATIC\",\\n          \"value\": \"eJxrYJmqyAABPbK+pm75RanJicUlmXnp+ulFmSnxKWnxmXklesnFZVP0AARuDb8=\"\\n        },\\n        \"config\": {\\n          \"dtype\": \"Any\",\\n          \"required\": \"false\",\\n          \"series\": false,\\n          \"adapter\": \"eJxrYJmqxgABPYJFiVX5RXppOfnlern5Kak5xVN6ePLy8wviE1MSC0pSi6ZMnqIHAF/+ELQ=\",\\n          \"validator\": \"eJxrYJmqwQABPYJFiVX5RXppOfnlern5Kak5xVN6+PLy8wviyxJzMlMSS/KLpkyeogcAg2wRnQ==\",\\n          \"source_id\": \"2a5f536f-20e5-4dc9-a284-adc66882bcb2\",\\n          \"source_name\": \"config\",\\n          \"inferred_type\": \"BLOCK\",\\n          \"value\": null\\n        }\\n      },\\n      \"outputProperty\": {\\n        \"grid_pkl_path\": {\\n          \"series\": false,\\n          \"adapter\": \"eJxrYJmqxgABPYJFiVX5RXppOfnlern5Kak5xVN6ePLy8wviE1MSC0pSi6ZMnqIHAF/+ELQ=\",\\n          \"transport\": \"FILE\"\\n        }\\n      },\\n      \"resourceRequirement\": {\\n        \"cores\": 2,\\n        \"memory\": 20000,\\n        \"useGpu\": false,\\n        \"gpu\": 0,\\n        \"useGpuIfAvailable\": false,\\n        \"clusterConfiguration\": {\\n          \"worker\": null,\\n          \"workerCore\": null,\\n          \"workerMemory\": null,\\n          \"numberOfInstances\": null,\\n          \"maxServerCount\": null\\n        },\\n        \"additionalEnv\": {},\\n        \"runEnv\": \"PYTHON\"\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"process_id\": null,\\n      \"eta\": 0\\n    },\\n    {\\n      \"name\": \"Configs_1\",\\n      \"id\": \"2a5f536f-20e5-4dc9-a284-adc66882bcb2\",\\n      \"artifact_id\": null,\\n      \"class_name\": \"Configs\",\\n      \"code\": \"eJyNVd9vE0cQvjv/jEMCBAoqbWnVJ/MQOyQhPypERU1oqZWjCpFoH9B2fbvnvfh8d9zuJRgFqRUKBGnVPrB9aisVif+B/ndldu8cG8RDEyWenV3Pznzzzbe/lP+4M2OZH3nRC+OMJIE3CGlrylbyY5RSNiIpFhTxAQ2piCPkhZhz9VI1mSXPoyEefGhP1ntZEIog4kqWxSih4JS1Thz5QZ8r5jRZuclqrM4qshr39qgn4MCRegKHECKxh5Byufxi099Y8fy1tTXfW1311wju+deWN8jK5jpepkvrPeUKtQPfasoGQsOYZCGFb8o6LHAQafM0QjiKYoFFEEccPHBF1TN5KDmD4oRCdXEK9/apCAQd6kQXUvw4Tlt+GB+04kwkmYAyqneNpferUFEQQYDSzWgEjmeQBGcX2KdXfjXJVELco6FyZZXTNKBcvZBlRsMEPDkY7HNZjvAQjAtyRqQ44kmcCiU/mrr4xA13z90OQrp7cu6lKi6aCTgaX8GarqyIGHoH18xyGhGaInPclXMp9WiwP3E0HmY0g8YFj6nqWvI0wxwFUSACHIKLqBdZTzZ0qshj1BuoY1iX0ixS0PR55AdhiPws8jSoBRVOT6hgtsAN3jlU8ACNSVDvxITu6sURoNbs2l2r63Rnup3OKrGJQ0qk3Nf/K6RKaqROZvpV0iCz5BSZ+6v2xD609qx/7EP7lW1bxLpnKV01xyEgsD2qSScgStrwV9O9RHpVIzQRxqp6ODfqHFpOx6Zmtzab29dug9vDHPLtt01QBF2A5PcBFmIo1PL4vpKfvXeUAh5JGniU5/uX3t33IFREcGo2m7K6e3Pn261d4N+Wewvt7ty84yrZ2IYPdMe9tfUj9DuA7j1CXhxmQz1CjTyNBAum5Gx+U7GaGwfP1wJ+gVQlzdRnMHuQmg88JcAKWF6+HiQjweJoMYjgxOLK4tKKj731zY11H/s3FFvrVjoLVsmxHcexy868DZZdd9SVK3rQvv8PfjTvZhHc5g1wX4+bq+dNsxlsdi57XkxkrR/GPRxyPXF1Qn2chUBlmADIRWjnPGgNz6APgG5G9VY1H2GIwppsDbKONZcvoilRQjzr5ae4egBYTA23uehhhkMzWXK2UJuWpq1sDA4mOWRiB2YfmSk1BcwjNCE7eI71ibNTw9gLY28Ajah8ow0z8k8Um9MahVc9b/kqXlqm6/7qsrb81fWNpY2rBF/tLZPNE41iCyyTZxAysZBpQCFIZ8fOQmyMF/TkSy4Xxlsw5vum7eYbIGu5iKEcPeXC8YqsJ6lWNDEyQ7nRZF+xr/MRs7uV7rnOgrAOLWIfW39axPm79NSBAXKlo4WyNo70PNdCLEQKI8ruHym52mbxkLb34v0RjtoHcTpotwo0F8Ogx9sGqbZGqp0j1UpGMG8QRtBUdV91HMtWrHmkDI26tkYDycYEYMV+BnCARyAthke/jXnECEDhu6wPH8EDQAWzPZYBP35nA5eF4IlgJ5GXc/0ZA9C6DnkA+260iiRYqtt+goljZKcMmJw5BlE5tg7tp6VCUlzIk92XlRyPZ5CMFvK8lNdFKcaD/Ai285ocpj6ccRM6k8lzRW/REKBFRbSXihbFvP6fxfDpYlzDLI2alm6N2vvV3etcElouLS2XYDmHUOcrZ1In22dvQKThWeBiHOU5NJ01QS3q17lIQb9AF950nU7Zchr2u0owXfE+O+BQNsQ0hbtsz4XC3kwX1gSKliAmFM6hyk+8lGrx9aNJgZNaTInyFEL0EfUyEGzN0vNTMzn2w1iehVkXoJA03SqckzeyYhgJNK94IMkcOgU6Q4dxOlLb/87KUj/JzBMInwie0zjRYoJDeLNLNAItr/7w0+53d10FL+AFZMZf5wjPRuSBYMRZJIDQkGrrLePkilM=\",\\n      \"isPublishedBlock\": false,\\n      \"source\": null,\\n      \"inputProperty\": {},\\n      \"outputProperty\": {\\n        \"config\": {\\n          \"series\": false,\\n          \"adapter\": \"eJxrYJmqxgABPYJFiVX5RXppOfnlern5Kak5xVN6ePLy8wviE1MSC0pSi6ZMnqIHAF/+ELQ=\",\\n          \"transport\": \"FILE\"\\n        }\\n      },\\n      \"resourceRequirement\": {\\n        \"cores\": 2,\\n        \"memory\": 3000,\\n        \"useGpu\": false,\\n        \"gpu\": 0,\\n        \"useGpuIfAvailable\": false,\\n        \"clusterConfiguration\": {\\n          \"worker\": null,\\n          \"workerCore\": null,\\n          \"workerMemory\": null,\\n          \"numberOfInstances\": null,\\n          \"maxServerCount\": null\\n        },\\n        \"additionalEnv\": {},\\n        \"runEnv\": \"PYTHON\"\\n      },\\n      \"executionType\": \"BlockExecutor\",\\n      \"dependencies\": [],\\n      \"system_dependencies\": null,\\n      \"meta_data\": null,\\n      \"process_id\": null,\\n      \"eta\": 0\\n    }\\n  ],\\n  \"connections\": [\\n    {\\n      \"source_block_id\": \"2a5f536f-20e5-4dc9-a284-adc66882bcb2\",\\n      \"target_block_id\": \"4951e7f5-57c8-465f-8bbc-c3cadf6ce0d0\",\\n      \"source_output\": \"config\",\\n      \"target_input\": \"config\"\\n    }\\n  ],\\n  \"priority\": \"LOW\",\\n  \"infraResourceEstimation\": null,\\n  \"resourceRequirement\": {\\n    \"cores\": null,\\n    \"memory\": null,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"comments\": null,\\n  \"order\": null,\\n  \"uiData\": null,\\n  \"dom\": null,\\n  \"systemGenerated\": false,\\n  \"systemModel\": false,\\n  \"pipelineVariableList\": [],\\n  \"pipelineTemplateVersion\": 0.0,\\n  \"versionId\": null,\\n  \"engineId\": \"65ed2499-f8c9-4c4d-ad27-aa689bd1531e\",\\n  \"userId\": \"c4080201-ccc9-4657-a457-7e18c100ff28\",\\n  \"runInitiatedFrom\": \"JUPYTER\",\\n  \"processList\": null,\\n  \"processInfo\": null\\n}', dom='Yet to add', order=None, infra_resource='{\\n  \"zookeeper\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  },\\n  \"kafka\": {\\n    \"cores\": 1,\\n    \"memory\": 1024,\\n    \"useGpu\": null,\\n    \"gpu\": null,\\n    \"useGpuIfAvailable\": null,\\n    \"clusterConfiguration\": null,\\n    \"additionalEnv\": {},\\n    \"runEnv\": null\\n  }\\n}', resource_spec=ResourceAllocated(cores=None, memory=None, use_gpu=None, gpu=None, use_gpu_if_available=None, cluster_configuration=None, additional_env={}, run_env=None), engine_id='65ed2499-f8c9-4c4d-ad27-aa689bd1531e', run_initiated_from='JUPYTER')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
